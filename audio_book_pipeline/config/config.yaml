paths:
  input_dir: "data/input_audio_video/"
  output_dir: "output/"
  intermediate_dir: "output/intermediate/"
  log_file: "output/logs/pipeline.log"
  cache_dir: "output/intermediate/cache/"

audio_processing:
  sample_rate: 16000
  audio_codec: "pcm_s16le"

transcription:
  whisper_model_name: "large-v2"
  language: "en"
  batch_size: 32
  compute_type: "float16"
  device: "cuda"
  srt_max_text_len: 120
  srt_max_interval_sec: 1.5

srt_processing:
  chapter_pattern_int_rg: 'Chapter\s+\d+\b[\s:.]*'
  timestamp_pattern_rg: '\s*\[\s*(\d{2}:\d{2}:\d{2},\d{3})\s*,\s*(\d{2}:\d{2}:\d{2},\d{3})\s*\]\s*'

llm:
  model_name: "gemini-2.0-flash"
  temperature: 0.7
  prompt_file: "config/prompt.txt"
  min_snippet_word_count: 5
  similarity_threshold: 0.4
  process_chunks_mode: "auto"
  max_words_for_single_prompt: 8000

snippet_extraction:
  output_format: "mp3"
  merge_proximity_ms: 1000
  end_time_buffer_ms: 100

logging:
  level: "INFO"