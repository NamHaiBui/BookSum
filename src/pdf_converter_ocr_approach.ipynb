{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This encompasses the approach to text processing with a more OCR approach.\n",
    "1. Gray-scale ->  Blur image -> draw ROI of blurred dark area -> Retrieve ROI as Rect -> Extract text using Rect with PyMuPDF\n",
    "2. Possible drawback:\n",
    "- Inability to detect text in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import difflib\n",
    "import threading\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "class MedianFinder(object):\n",
    "    def __init__(self):\n",
    "        self.minheap = []\n",
    "        self.maxheap = []\n",
    "\n",
    "    def addNum(self, num:float):\n",
    "        if not self.minheap and not self.maxheap:\n",
    "            heapq.heappush(self.maxheap, -num)\n",
    "        else:\n",
    "            if len(self.minheap)== len(self.maxheap):\n",
    "                if -self.maxheap[0]<=num:\n",
    "                    heapq.heappush(self.minheap, num)\n",
    "                    heapq.heappush(self.maxheap, -heapq.heappop(self.minheap))\n",
    "                else:\n",
    "                    heapq.heappush(self.maxheap, -num)\n",
    "            else:\n",
    "                if -self.maxheap[0]<= num:\n",
    "                    heapq.heappush(self.minheap, num)\n",
    "                else:\n",
    "                    heapq.heappush(self.minheap, -heapq.heappop(self.maxheap))\n",
    "                    heapq.heappush(self.maxheap, -num)\n",
    "                \n",
    "    def findMedian(self):\n",
    "        if len(self.minheap)==len(self.maxheap):\n",
    "            return (self.minheap[0]-self.maxheap[0])/2.0\n",
    "        else:\n",
    "            return -self.maxheap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Node:\n",
    "    def __init__(self, content):\n",
    "        self.content = content\n",
    "        self.children = []\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "    def __str__(self):\n",
    "        return f\"Node({self.content}, {self.children})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_merge(\n",
    "    rect1: pymupdf.Rect,\n",
    "    rect2: pymupdf.Rect,\n",
    "    h_threshold: float = 4,\n",
    "    v_threshold: float = 1,\n",
    "    same_line_height_factor: float = 0.75, \n",
    "    min_h_overlap_factor: float = 0.75   # Factor for 'significant' horizontal overlap\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Determine if two rectangles should be merged based on proximity or overlap.\n",
    "\n",
    "    Args:\n",
    "        rect1, rect2: PyMuPDF Rect objects to compare.\n",
    "        h_threshold: Maximum horizontal gap allowed for merging adjacent rectangles\n",
    "                     on the same line.\n",
    "        v_threshold: Maximum vertical gap allowed for merging rectangles that\n",
    "                     have significant horizontal overlap.\n",
    "        same_line_height_factor: Multiplier for average height to determine if\n",
    "                                 rectangles are on the same line (based on y0 diff).\n",
    "        min_h_overlap_factor: Minimum horizontal overlap (as a fraction of the *smaller* width) required to consider vertical merging.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if rectangles should be merged, False otherwise.\n",
    "    \"\"\"\n",
    "    # --- Basic Properties and Checks ---\n",
    "    if not rect1 or not rect2 or rect1.is_empty or rect2.is_empty:\n",
    "        return False # Cannot merge with invalid or empty rectangles\n",
    "\n",
    "    height1 = rect1.height\n",
    "    height2 = rect2.height\n",
    "    # Avoid division by zero if heights are zero\n",
    "    avg_height = (height1 + height2) / 2.0 if (height1 + height2) > 0 else 0\n",
    "\n",
    "    # --- Condition 1: Horizontal Proximity on Same Line ---\n",
    "    # Check if vertically aligned enough to be on the same 'line'\n",
    "    # Use y-centers for potentially better alignment check than just y0\n",
    "    # is_same_line = abs(rect1.y0 - rect2.y0) < avg_height * same_line_height_factor\n",
    "    y_center1 = rect1.y0 + height1 / 2.0\n",
    "    y_center2 = rect2.y0 + height2 / 2.0\n",
    "    # Rects are on same line if vertical distance between centers is less than avg height\n",
    "    is_same_line = abs(y_center1 - y_center2) < avg_height if avg_height > 0 else (rect1.y0 == rect2.y0)\n",
    "\n",
    "\n",
    "    # Calculate horizontal gap (only if they don't overlap horizontally)\n",
    "    h_gap = -1.0\n",
    "    if rect1.x1 <= rect2.x0: # rect1 is left of rect2\n",
    "        h_gap = rect2.x0 - rect1.x1\n",
    "    elif rect2.x1 <= rect1.x0: # rect2 is left of rect1\n",
    "        h_gap = rect1.x0 - rect2.x1\n",
    "\n",
    "    if is_same_line and h_gap >= 0 and h_gap < h_threshold:\n",
    "        # print(f\"H-Merge: {rect1} & {rect2} (gap {h_gap:.2f})\") # Debug\n",
    "        return True # Merge if close horizontally on the same line\n",
    "\n",
    "    # --- Condition 2: Vertical Proximity with Significant Horizontal Overlap ---\n",
    "    # Calculate horizontal overlap width\n",
    "    h_overlap_width = max(0.0, min(rect1.x1, rect2.x1) - max(rect1.x0, rect2.x0))\n",
    "\n",
    "    # Check if horizontal overlap is significant\n",
    "    min_width = min(rect1.width, rect2.width)\n",
    "    has_significant_h_overlap = False\n",
    "    if min_width > 0 and h_overlap_width / min_width >= min_h_overlap_factor:\n",
    "        has_significant_h_overlap = True\n",
    "    elif h_overlap_width > 0 and min_width <= 0: # Overlap exists, one rect has no width? Consider overlap significant.\n",
    "        has_significant_h_overlap = True\n",
    "    # Alternative check: One rect is contained horizontally within the other\n",
    "    is_contained_horizontally = (rect1.x0 >= rect2.x0 and rect1.x1 <= rect2.x1) or \\\n",
    "                                (rect2.x0 >= rect1.x0 and rect2.x1 <= rect1.x1)\n",
    "\n",
    "    if has_significant_h_overlap or is_contained_horizontally:\n",
    "        # Calculate vertical gap (only if they don't overlap vertically)\n",
    "        v_gap = -1.0\n",
    "        if rect1.y1 <= rect2.y0: # rect1 is above rect2\n",
    "            v_gap = rect2.y0 - rect1.y1\n",
    "        elif rect2.y1 <= rect1.y0: # rect2 is above rect1\n",
    "            v_gap = rect1.y0 - rect2.y1\n",
    "\n",
    "        if v_gap >= 0 and v_gap < v_threshold:\n",
    "            # print(f\"V-Merge: {rect1} & {rect2} (gap {v_gap:.2f})\") # Debug\n",
    "            return True # Merge if close vertically and overlap significantly horizontally\n",
    "\n",
    "    # --- Condition 3: Direct Overlap (Optional but good fallback) ---\n",
    "    # Check if rectangles intersect (overlap) significantly in both dimensions?\n",
    "    # The previous checks cover proximity *near* overlap.\n",
    "    # If they actually overlap, should they always merge? Often yes.\n",
    "    # Calculate vertical overlap\n",
    "    v_overlap_height = max(0.0, min(rect1.y1, rect2.y1) - max(rect1.y0, rect2.y0))\n",
    "\n",
    "    # If they overlap both horizontally and vertically, merge them.\n",
    "    if h_overlap_width > 0 and v_overlap_height > 0:\n",
    "        # print(f\"O-Merge: {rect1} & {rect2}\") # Debug\n",
    "        return True\n",
    "\n",
    "    return False # No merge conditions met\n",
    "def merge_text_regions(regions, iterations=3):\n",
    "    \"\"\"\n",
    "    Merge text regions that are close to each other.\n",
    "    \n",
    "    Args:\n",
    "        regions: List of PyMuPDF Rect objects\n",
    "        iterations: Number of merging passes to perform\n",
    "    Returns:\n",
    "        list: Merged PyMuPDF Rect objects\n",
    "    \"\"\"\n",
    "    if not regions:\n",
    "        return []\n",
    "    \n",
    "    # Perform multiple iterations of merging to handle chains of regions\n",
    "    for _ in range(iterations):\n",
    "        merged = False\n",
    "        i = 0\n",
    "        while i < len(regions):\n",
    "            j = i + 1\n",
    "            while j < len(regions):\n",
    "                if should_merge(regions[i], regions[j], h_threshold=6, v_threshold=1): # Make this more relative\n",
    "                    # Merge rectangles\n",
    "                    merged_rect = pymupdf.Rect(\n",
    "                        min(regions[i].x0, regions[j].x0),\n",
    "                        min(regions[i].y0, regions[j].y0),\n",
    "                        max(regions[i].x1, regions[j].x1),\n",
    "                        max(regions[i].y1, regions[j].y1)\n",
    "                    )\n",
    "                    regions[i] = merged_rect\n",
    "                    regions.pop(j)\n",
    "                    merged = True\n",
    "                else:\n",
    "                    j += 1\n",
    "            i += 1\n",
    "            \n",
    "        if not merged:\n",
    "            break\n",
    "            \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_ocr_approach(pdf_path, page_num=0, visual_proof = False, is_multi_column = False):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF using image processing to identify text regions.\n",
    "    With text region merging to combine related text blocks.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file\n",
    "        page_num (int): Page number to process (0-indexed)\n",
    "        \n",
    "    Returns:\n",
    "        list: Extracted text segments from identified regions\n",
    "    \"\"\"\n",
    "    # Open the PDF\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    page = doc[page_num]\n",
    "    zoom_factor = 2\n",
    "    # Convert page to image\n",
    "    pix = page.get_pixmap(matrix=pymupdf.Matrix(zoom_factor, zoom_factor))\n",
    "    img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.h, pix.w, pix.n)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    if img.shape[2] >= 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img[:, :, 0]\n",
    "    # Apply Gaussian blur\n",
    "    adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 13, 2)\n",
    "    rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (8, 8))\n",
    "    \n",
    "    dilated = cv2.dilate(adaptive, rectKernel, iterations=1)\n",
    "    \n",
    "    closing = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, rectKernel)\n",
    "    \n",
    "    edged = cv2.Canny(closing, 50, 200, apertureSize=3)\n",
    "\n",
    "    contours, _  = cv2.findContours(\n",
    "        edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    \n",
    "    # Create ROIs from contours\n",
    "    initial_regions = []\n",
    "    for cnt in contours:\n",
    "        \n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        # Convert back to PDF coordinates (accounting for the zoom factor)\n",
    "        pdf_x, pdf_y = x/zoom_factor, y/zoom_factor\n",
    "        pdf_w, pdf_h = w/zoom_factor, h/zoom_factor\n",
    "        \n",
    "        # Create PyMuPDF rect\n",
    "        rect = pymupdf.Rect(pdf_x, pdf_y, pdf_x + pdf_w, pdf_y + pdf_h)\n",
    "        initial_regions.append(rect)\n",
    "    \n",
    "    # Merge text regions that are close to each other\n",
    "    merged_regions = merge_text_regions(initial_regions, iterations=6)\n",
    "    merged_regions = [r for r in merged_regions if (r.x1 - r.x0) > 8 and (r.y1 - r.y0) > 8]  \n",
    "    \n",
    "    text_regions = []\n",
    "    \n",
    "    words = page.get_text(\"words\")\n",
    "    \n",
    "    for rect in sorted(merged_regions, key=lambda r: [(r.y1- r.y0) * (r.x1 -r.x0), r.y0, r.x0]):\n",
    "        text_height_collection = MedianFinder()\n",
    "        text = \"\"\n",
    "        idx = 0\n",
    "        min_text_height = 1000000\n",
    "        # Add relative padding to the rect to ensure we catch words that are nearby\n",
    "        padding = 1.5  # pixels in PDF coordinate space\n",
    "        rect = pymupdf.Rect(\n",
    "            rect.x0 - padding,\n",
    "            rect.y0 - padding,\n",
    "            rect.x1 + padding,\n",
    "            rect.y1 + padding\n",
    "        )\n",
    "        # Iterate through words and pick out words that fall within the rect\n",
    "        prev_y = words[0][1] if words else 0\n",
    "        while words and idx < len(words):\n",
    "            current_word = words[idx]\n",
    "            word_rect = pymupdf.Rect(current_word[:4])\n",
    "            \n",
    "            if word_rect.intersects(rect) or rect.contains(word_rect):        \n",
    "                text_height_collection.addNum(word_rect.height)\n",
    "                min_text_height = min(min_text_height, word_rect.height) \n",
    "                text += current_word[4] + (\" \" if abs(prev_y - current_word[1]) <= abs(current_word[1] - current_word[3])*0.6 else \"\\n\")\n",
    "                prev_y = current_word[1]\n",
    "                words.pop(idx)\n",
    "            else:\n",
    "                idx += 1\n",
    "        \n",
    "        if text.strip():\n",
    "            if text.strip().isdigit():\n",
    "                continue\n",
    "            text_regions.append({\"occupy_space\": rect,\n",
    "                                 \"content\": text, \n",
    "                                 \"text_height_median\": text_height_collection.findMedian(), \n",
    "                                 \"min_height\": min_text_height, \n",
    "                                 \"page_num\": page_num})\n",
    "    # print(words)\n",
    "    if visual_proof:\n",
    "        viz_img = img.copy()\n",
    "        for item in merged_regions:\n",
    "            rect = item[\"occupy_space\"]\n",
    "            # Convert back to image coordinates\n",
    "            x0, y0, x1, y1 = rect.x0*zoom_factor, rect.y0*zoom_factor, rect.x1*zoom_factor, rect.y1*zoom_factor\n",
    "            cv2.rectangle(viz_img, (int(x0), int(y0)), (int(x1), int(y1)), (0, 255, 0), 2)\n",
    "        \n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(edged, cmap='gray')\n",
    "        plt.title(\"Processed Image\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(viz_img)\n",
    "        plt.title(f\"Merged Text Regions: {len(text_regions)} blocks\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    return text_regions[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "def extract_page_text_via_image_regions(\n",
    "    page: pymupdf.Page,\n",
    "    zoom_factor: int = 2,\n",
    "    adaptive_thresh_block_size: int = 13, # Must be odd > 1\n",
    "    adaptive_thresh_c: int = 2,\n",
    "    morph_kernel_size: tuple = (8, 8),\n",
    "    dilate_iterations: int = 1,\n",
    "    canny_thresh1: int = 50,\n",
    "    canny_thresh2: int = 200,\n",
    "    min_region_width: float = 8.0, # In PDF points\n",
    "    min_region_height: float = 8.0, # In PDF points\n",
    "    merge_iterations: int = 6,\n",
    "    region_padding: float = 0.3, # Padding around merged regions for word capture (PDF points)\n",
    "    line_break_threshold: float = 0.6, # Factor of word height to detect line breaks\n",
    "    filter_numeric_blocks: bool = True, # Skip blocks containing only digits\n",
    "    handle_unassigned_words: bool = False, # Option to process words not in any region\n",
    "    visual_proof: bool = False\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF page by detecting text regions using OpenCV\n",
    "    on a rendered image, merging regions, and then extracting PyMuPDF text\n",
    "    within those regions.\n",
    "\n",
    "    Args:\n",
    "        page: The pymupdf.Page object to process.\n",
    "        zoom_factor: Factor to render the page image (higher zoom = more detail, slower).\n",
    "        adaptive_thresh_block_size: Block size for OpenCV adaptive thresholding.\n",
    "        adaptive_thresh_c: Constant subtracted in adaptive thresholding.\n",
    "        morph_kernel_size: Kernel size for morphological operations (dilation, closing).\n",
    "        dilate_iterations: Number of iterations for dilation.\n",
    "        canny_thresh1: Lower threshold for Canny edge detection.\n",
    "        canny_thresh2: Upper threshold for Canny edge detection.\n",
    "        min_region_width: Minimum width of a valid detected region (in PDF points).\n",
    "        min_region_height: Minimum height of a valid detected region (in PDF points).\n",
    "        merge_iterations: Iterations for the (abstracted) merge_text_regions function.\n",
    "        region_padding: Padding added around merged regions before capturing words.\n",
    "        line_break_threshold: Factor of word height used in heuristic line break detection.\n",
    "        filter_numeric_blocks: If True, blocks containing only digits are discarded.\n",
    "        handle_unassigned_words: If True, attempt to process words not captured (NYI).\n",
    "        visual_proof: If True, display intermediate processing images using matplotlib.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, where each dictionary represents a detected\n",
    "        text block and contains:\n",
    "        - \"occupy_space\": The pymupdf.Rect of the merged region.\n",
    "        - \"content\": The extracted text content (str).\n",
    "        - \"text_height_median\": The median height of words in the block (float).\n",
    "        - \"min_height\": The minimum height of words in the block (float).\n",
    "        - \"page_num\": The page number (0-indexed).\n",
    "    \"\"\"\n",
    "    print(f\"Processing Page {page.number} via Image Regions...\")\n",
    "\n",
    "    # 1. Render Page to Image\n",
    "    try:\n",
    "        mat = pymupdf.Matrix(zoom_factor, zoom_factor)\n",
    "        pix = page.get_pixmap(matrix=mat)\n",
    "        img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.h, pix.w, pix.n)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error rendering page {page.number} to pixmap: {e}\")\n",
    "        return []\n",
    "\n",
    "    # 2. OpenCV Image Processing to Find Contours\n",
    "    # Convert to grayscale\n",
    "    if img.shape[2] >= 3: # Check if color channels exist\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    elif img.shape[2] == 1:\n",
    "         gray = img[:, :, 0]\n",
    "    else: # Handle unexpected image format\n",
    "         print(f\"  Warning: Unexpected image format with shape {img.shape}. Trying first channel.\")\n",
    "         gray = img[:, :, 0] if len(img.shape) > 2 and img.shape[2] > 0 else img\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                     cv2.THRESH_BINARY_INV, adaptive_thresh_block_size, adaptive_thresh_c)\n",
    "\n",
    "    # Morphological operations to connect characters/words into text block shapes\n",
    "    rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, morph_kernel_size)\n",
    "    dilated = cv2.dilate(adaptive, rectKernel, iterations=dilate_iterations)\n",
    "    closing = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, rectKernel) \n",
    "\n",
    "    # Canny edge detection (sometimes helps refine contours)\n",
    "    edged = cv2.Canny(closing, canny_thresh1, canny_thresh2, apertureSize=3)\n",
    "\n",
    "    # Find external contours\n",
    "    contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(f\"  Found {len(contours)} initial contours.\")\n",
    "\n",
    "    # 3. Create Initial Regions from Contours\n",
    "    initial_regions = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        # Convert back to PDF coordinates\n",
    "        pdf_x0, pdf_y0 = x / zoom_factor, y / zoom_factor\n",
    "        pdf_x1, pdf_y1 = (x + w) / zoom_factor, (y + h) / zoom_factor\n",
    "        rect = pymupdf.Rect(pdf_x0, pdf_y0, pdf_x1, pdf_y1)\n",
    "\n",
    "        if rect.width >= min_region_width / 2 and rect.height >= min_region_height / 2: # Looser pre-filter\n",
    "             initial_regions.append(rect)\n",
    "\n",
    "    print(f\"  Created {len(initial_regions)} initial regions after pre-filtering.\")\n",
    "\n",
    "    # 4. Merge Overlapping/Nearby Regions (Abstracted Call)\n",
    "    merged_regions = merge_text_regions(initial_regions, iterations=merge_iterations)\n",
    "\n",
    "    # Filter out regions that are too small after merging\n",
    "    final_regions = [r for r in merged_regions\n",
    "                     if r.width >= min_region_width and r.height >= min_region_height]\n",
    "    print(f\"  {len(final_regions)} regions remaining after merging and size filtering.\")\n",
    "\n",
    "    # Sort final regions by reading order (top-to-bottom, left-to-right)\n",
    "    final_regions.sort(key=lambda r: (r.y0, r.x0))\n",
    "\n",
    "    # 5. Extract Text Words using PyMuPDF\n",
    "    words_data = page.get_text(\"words\") # Format: (x0, y0, x1, y1, word, block_no, line_no, word_no)\n",
    "    if not words_data:\n",
    "        print(f\"  No text words found on page {page.number} by PyMuPDF.\")\n",
    "        return []\n",
    "\n",
    "    # Prepare word items with rectangles and assignment status\n",
    "    word_items = [{\n",
    "        \"rect\": pymupdf.Rect(w[:4]),\n",
    "        \"text\": w[4],\n",
    "        \"baseline\": w[1], \n",
    "        \"height\": pymupdf.Rect(w[:4]).height,\n",
    "        \"assigned\": False\n",
    "    } for w in words_data]\n",
    "\n",
    "    # 6. Assign Words to Regions and Reconstruct Text Blocks\n",
    "    extracted_blocks = []\n",
    "    for region_rect in final_regions:\n",
    "        # print(f\"  Processing region: {region_rect}\")\n",
    "        # Define the padded capture area for the current region\n",
    "        padded_rect = pymupdf.Rect(region_rect.x0 - region_padding,\n",
    "                                   region_rect.y0 - region_padding,\n",
    "                                   region_rect.x1 + region_padding,\n",
    "                                   region_rect.y1 + region_padding)\n",
    "        \n",
    "        words_in_region_indices = []\n",
    "        median_finder = MedianFinder() \n",
    "        # Find unassigned words that intersect the padded region\n",
    "        for idx, item in enumerate(word_items):\n",
    "            if not item[\"assigned\"] and item[\"rect\"].intersects(padded_rect):\n",
    "                words_in_region_indices.append(idx)\n",
    "                median_finder.addNum(item[\"height\"])\n",
    "                item[\"assigned\"] = True \n",
    "                \n",
    "        if not words_in_region_indices:\n",
    "            # print(padded_rect)\n",
    "            continue \n",
    "        current_block_words = [word_items[i] for i in words_in_region_indices]\n",
    "        current_block_words.sort(key=lambda w: (w[\"rect\"].y0, w[\"rect\"].x0))\n",
    "\n",
    "        \n",
    "        block_text = \"\"\n",
    "        min_height_in_block = float('inf')\n",
    "        prev_baseline = current_block_words[0][\"baseline\"] if current_block_words else 0\n",
    "\n",
    "        for word_item in current_block_words:\n",
    "            current_baseline = word_item[\"baseline\"]\n",
    "            current_height = word_item[\"height\"]\n",
    "            if current_height > 0: \n",
    "                 min_height_in_block = min(min_height_in_block, current_height)\n",
    "            # Heuristic: Check vertical distance between baselines relative to current word height\n",
    "            # Use a small tolerance (e.g., 1 PDF point) for exact same baseline match\n",
    "            vertical_distance = abs(prev_baseline - current_baseline)\n",
    "            is_same_line = vertical_distance < current_height*0.75 or (current_height > 0 and vertical_distance <= current_height * line_break_threshold)\n",
    "\n",
    "            separator = \" \" if is_same_line else \"\\n\"\n",
    "            if block_text: \n",
    "                block_text += separator\n",
    "            block_text += word_item[\"text\"]\n",
    "            prev_baseline = current_baseline \n",
    "\n",
    "        content = block_text.strip()\n",
    "        if not content: continue \n",
    "\n",
    "        if filter_numeric_blocks and content.isdigit():\n",
    "            print(f\"  Skipping numeric block: '{content}'\")\n",
    "            continue\n",
    "\n",
    "        # Store the extracted block information\n",
    "        extracted_blocks.append({\n",
    "            \"occupy_space\": region_rect, \n",
    "            \"content\": content,\n",
    "            \"text_height_median\": median_finder.findMedian(),\n",
    "            \"min_height\": min_height_in_block if min_height_in_block != float('inf') else 0,\n",
    "            \"page_num\": page.number\n",
    "        })\n",
    "\n",
    "    print(f\"  Extracted {len(extracted_blocks)} text blocks.\")\n",
    "\n",
    "    # 7.  Handle Unassigned Words (Not Yet Implemented)\n",
    "    unassigned_word_count = sum(1 for item in word_items if not item[\"assigned\"])\n",
    "    # print(*[(item[\"rect\"], item[\"text\"]) for item in word_items if not item[\"assigned\"]], sep=\"\\n\")\n",
    "    if unassigned_word_count > 0:\n",
    "        print(f\"  Warning: {unassigned_word_count} words were not assigned to any detected region.\")\n",
    "        if handle_unassigned_words:\n",
    "            # --- Add logic here to potentially group/process unassigned words ---\n",
    "            # Could involve creating default blocks based on proximity, line numbers etc.\n",
    "            print(\"(Handling unassigned words not implemented)\")\n",
    "            pass\n",
    "        # --- End NYI section ---\n",
    "\n",
    "\n",
    "    # 8. Visual Proof (Optional)\n",
    "    if visual_proof:\n",
    "        try:\n",
    "            viz_img = img.copy()\n",
    "            # Draw final merged regions used for text extraction\n",
    "            for item in extracted_blocks:\n",
    "                rect = item[\"occupy_space\"]\n",
    "                # rect = item\n",
    "                # print(item)\n",
    "                # Convert PDF rect back to image coordinates for drawing\n",
    "                x0, y0 = int(rect.x0 * zoom_factor), int(rect.y0 * zoom_factor)\n",
    "                x1, y1 = int(rect.x1 * zoom_factor), int(rect.y1 * zoom_factor)\n",
    "                cv2.rectangle(viz_img, (x0, y0), (x1, y1), (0, 255, 0), 2) # Green boxes\n",
    "\n",
    "            plt.figure(figsize=(15, 15))\n",
    "\n",
    "            # Show edge/contour image\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(edged, cmap='gray')\n",
    "            plt.title(f\"Page {page.number} - Edges\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Show original image with detected regions overlaid\n",
    "            plt.subplot(1, 2, 2)\n",
    "            # Convert viz_img from BGR (OpenCV default) to RGB (matplotlib default) if necessary\n",
    "            if viz_img.shape[2] == 3:\n",
    "                viz_img_rgb = cv2.cvtColor(viz_img, cv2.COLOR_BGR2RGB)\n",
    "                plt.imshow(viz_img_rgb)\n",
    "            else: # Grayscale\n",
    "                 plt.imshow(viz_img, cmap='gray')\n",
    "\n",
    "            plt.title(f\"Page {page.number} - Detected Text Regions ({len(extracted_blocks)} blocks)\")\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"  Error generating visual proof: {e}\")\n",
    "\n",
    "\n",
    "    return extracted_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(pdf_path:str)-> tuple[List[dict], str]:\n",
    "    \"\"\"PyMuPDF-based function to extract text with bounding boxes from a PDF file.\"\"\"\n",
    "    try:\n",
    "        doc = pymupdf.open(pdf_path, filetype=\"pdf\")\n",
    "        prev_block = None\n",
    "        all_blocks = []\n",
    "        for page_num, page in enumerate(doc):\n",
    "            words = page.get_text(\"words\")\n",
    "            page_block = []\n",
    "            # Take threshold based on page_width and page_height\n",
    "            WIDTH_threshold = (0.02 if page.rect.width > page.rect.height else 0.0092625) * page.rect.width\n",
    "            HEIGHT_threshold = (0.01 if page.rect.width > page.rect.height else 0.05) * page.rect.height\n",
    "            for curr_word in words:\n",
    "                # Each block is (x0, y0, x1, y1, text, block_no, block_type)\n",
    "                x0, y0, x1, y1, text, block_no, line_no, block_type = curr_word\n",
    "                text_height = y1 - y0\n",
    "                if not text.strip():\n",
    "                    continue\n",
    "                is_mergable = False\n",
    "                \n",
    "                \"\"\"\n",
    "                Check if the current block is close to the previous block.\n",
    "                The conditions are:\n",
    "                (1. The x-coordinates of the current block are within WIDTH_threshold of the previous block.\n",
    "                2. The y-coordinates of the current block are within HEIGHT_threshold of the previous block.\n",
    "                (3. The current block is not completely to the left of the previous block.\n",
    "                4. The y-coordinates of the current block are within 4 pixels of the previous block.\n",
    "                5. The current block is not completely to the right of the previous block.\n",
    "                \"\"\"\n",
    "                if prev_block and abs(text_height - prev_block[-1]) <= 0 and \\\n",
    "                    (\\\n",
    "                        (abs(x0 - prev_block[2]) <= WIDTH_threshold and (y0 -prev_block[3]) <= HEIGHT_threshold) \\\n",
    "                    ):\n",
    "                    prev_block[2] = max(prev_block[2], x1) \n",
    "                    prev_block[3] = max(prev_block[3], y1) \n",
    "                    prev_block[4] += \" \" + text.strip()\n",
    "                    is_mergable = True\n",
    "\n",
    "                if is_mergable and page_block:\n",
    "                    page_block.pop()\n",
    "                    page_block.append(\n",
    "                        {\n",
    "                            \"page\": page_num,\n",
    "                            \"bbox\": (prev_block[0], prev_block[1], prev_block[2], prev_block[3]),\n",
    "                            \"text\": prev_block[4],\n",
    "                            \"block_no\": block_no,\n",
    "                            \"block_type\": block_type,\n",
    "                            \"text_height\": prev_block[-1]\n",
    "                        }\n",
    "                    )    \n",
    "                    prev_block = [prev_block[0], prev_block[1], prev_block[2], prev_block[3], prev_block[4], block_no, block_type, prev_block[-1]]\n",
    "                else:\n",
    "                    page_block.append({\n",
    "                        \"page\": page_num,\n",
    "                        \"bbox\": (x0, y0, x1, y1),\n",
    "                        \"text\": text.strip(),\n",
    "                        \"block_no\": block_no,\n",
    "                        \"block_type\": block_type,\n",
    "                        \"text_height\": text_height\n",
    "                    })\n",
    "                    # Update the previous block\n",
    "                    prev_block = [x0, y0, x1, y1, text.strip(), block_no, block_type, text_height]\n",
    "            # merged_blocks = process_text_blocks(page_block, eps=25, min_samples=1)\n",
    "            all_blocks.extend(page_block)\n",
    "        doc.close()\n",
    "        # Remove empty blocks\n",
    "        if not all_blocks:\n",
    "            raise Exception(\"PyMuPDF Failed or No text found in the PDF.\")\n",
    "        return (all_blocks, 'pyMuPDF')\n",
    "    except Exception as e:\n",
    "        print(\"The Error is\", e.with_traceback())\n",
    "        # return extract_text_with_Mistral_OCR(pdf_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting processing for: D:\\DATA300\\AudioBookSum\\pdf\\Didi Huberman.pdf ---\n",
      "Processing 59 pages from Didi Huberman.pdf...\n",
      "Processing Page 0 via Image Regions...\n",
      "  Found 14 initial contours.\n",
      "  Created 14 initial regions after pre-filtering.\n",
      "  3 regions remaining after merging and size filtering.\n",
      "  No text words found on page 0 by PyMuPDF.\n",
      "Processing Page 1 via Image Regions...\n",
      "  Found 6 initial contours.\n",
      "  Created 6 initial regions after pre-filtering.\n",
      "  5 regions remaining after merging and size filtering.\n",
      "  Extracted 5 text blocks.\n",
      "Processing Page 2 via Image Regions...\n",
      "  Found 9 initial contours.\n",
      "  Created 9 initial regions after pre-filtering.\n",
      "  9 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '2002029382'\n",
      "  Extracted 8 text blocks.\n",
      "Processing Page 3 via Image Regions...\n",
      "  Found 23 initial contours.\n",
      "  Created 23 initial regions after pre-filtering.\n",
      "  19 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '1'\n",
      "  Skipping numeric block: '83'\n",
      "  Skipping numeric block: '283'\n",
      "  Extracted 16 text blocks.\n",
      "  Warning: 1 words were not assigned to any detected region.\n",
      "Processing Page 4 via Image Regions...\n",
      "  Found 9 initial contours.\n",
      "  Created 9 initial regions after pre-filtering.\n",
      "  9 regions remaining after merging and size filtering.\n",
      "  Extracted 9 text blocks.\n",
      "Processing Page 5 via Image Regions...\n",
      "  Found 6 initial contours.\n",
      "  Created 6 initial regions after pre-filtering.\n",
      "  5 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '2'\n",
      "  Skipping numeric block: '13'\n",
      "  Extracted 3 text blocks.\n",
      "Processing Page 6 via Image Regions...\n",
      "  Found 9 initial contours.\n",
      "  Created 9 initial regions after pre-filtering.\n",
      "  4 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '14'\n",
      "  Extracted 2 text blocks.\n",
      "Processing Page 7 via Image Regions...\n",
      "  Found 5 initial contours.\n",
      "  Created 5 initial regions after pre-filtering.\n",
      "  5 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '15'\n",
      "  Extracted 4 text blocks.\n",
      "Processing Page 8 via Image Regions...\n",
      "  Found 6 initial contours.\n",
      "  Created 6 initial regions after pre-filtering.\n",
      "  6 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '16'\n",
      "  Extracted 4 text blocks.\n",
      "Processing Page 9 via Image Regions...\n",
      "  Found 7 initial contours.\n",
      "  Created 7 initial regions after pre-filtering.\n",
      "  7 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '17'\n",
      "  Extracted 6 text blocks.\n",
      "Processing Page 10 via Image Regions...\n",
      "  Found 3 initial contours.\n",
      "  Created 3 initial regions after pre-filtering.\n",
      "  3 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '18'\n",
      "  Extracted 2 text blocks.\n",
      "Processing Page 11 via Image Regions...\n",
      "  Found 6 initial contours.\n",
      "  Created 6 initial regions after pre-filtering.\n",
      "  6 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '19'\n",
      "  Extracted 5 text blocks.\n",
      "Processing Page 12 via Image Regions...\n",
      "  Found 8 initial contours.\n",
      "  Created 8 initial regions after pre-filtering.\n",
      "  8 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '20'\n",
      "  Extracted 7 text blocks.\n",
      "Processing Page 13 via Image Regions...\n",
      "  Found 6 initial contours.\n",
      "  Created 6 initial regions after pre-filtering.\n",
      "  6 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '21'\n",
      "  Extracted 5 text blocks.\n",
      "Processing Page 14 via Image Regions...\n",
      "  Found 214 initial contours.\n",
      "  Created 214 initial regions after pre-filtering.\n",
      "  6 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '22'\n",
      "  Extracted 5 text blocks.\n",
      "Processing Page 15 via Image Regions...\n",
      "  Found 261 initial contours.\n",
      "  Created 261 initial regions after pre-filtering.\n",
      "  7 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '23'\n",
      "  Extracted 6 text blocks.\n",
      "Processing Page 16 via Image Regions...\n",
      "  Found 8 initial contours.\n",
      "  Created 8 initial regions after pre-filtering.\n",
      "  8 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '24'\n",
      "  Extracted 7 text blocks.\n",
      "Processing Page 17 via Image Regions...\n",
      "  Found 6 initial contours.\n",
      "  Created 6 initial regions after pre-filtering.\n",
      "  6 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '25'\n",
      "  Extracted 5 text blocks.\n",
      "Processing Page 18 via Image Regions...\n",
      "  Found 203 initial contours.\n",
      "  Created 203 initial regions after pre-filtering.\n",
      "  6 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '26'\n",
      "  Extracted 5 text blocks.\n",
      "Processing Page 19 via Image Regions...\n",
      "  Found 266 initial contours.\n",
      "  Created 266 initial regions after pre-filtering.\n",
      "  6 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '27'\n",
      "  Extracted 5 text blocks.\n",
      "Processing Page 20 via Image Regions...\n",
      "  Found 4 initial contours.\n",
      "  Created 4 initial regions after pre-filtering.\n",
      "  4 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '28'\n",
      "  Extracted 3 text blocks.\n",
      "Processing Page 21 via Image Regions...\n",
      "  Found 100 initial contours.\n",
      "  Created 100 initial regions after pre-filtering.\n",
      "  8 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '3'\n",
      "  Skipping numeric block: '29'\n",
      "  Extracted 6 text blocks.\n",
      "Processing Page 22 via Image Regions...\n",
      "  Found 5 initial contours.\n",
      "  Created 5 initial regions after pre-filtering.\n",
      "  5 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '30'\n",
      "  Extracted 4 text blocks.\n",
      "Processing Page 23 via Image Regions...\n",
      "  Found 4 initial contours.\n",
      "  Created 4 initial regions after pre-filtering.\n",
      "  4 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '31'\n",
      "  Extracted 1 text blocks.\n",
      "Processing Page 24 via Image Regions...\n",
      "  Found 6 initial contours.\n",
      "  Created 6 initial regions after pre-filtering.\n",
      "  6 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '32'\n",
      "  Extracted 5 text blocks.\n",
      "Processing Page 25 via Image Regions...\n",
      "  Found 7 initial contours.\n",
      "  Created 7 initial regions after pre-filtering.\n",
      "  7 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '33'\n",
      "  Extracted 6 text blocks.\n",
      "Processing Page 26 via Image Regions...\n",
      "  Found 20 initial contours.\n",
      "  Created 20 initial regions after pre-filtering.\n",
      "  7 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '34'\n",
      "  Extracted 6 text blocks.\n",
      "Processing Page 27 via Image Regions...\n",
      "  Found 7 initial contours.\n",
      "  Created 7 initial regions after pre-filtering.\n",
      "  7 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '35'\n",
      "  Extracted 6 text blocks.\n",
      "Processing Page 28 via Image Regions...\n",
      "  Found 3 initial contours.\n",
      "  Created 3 initial regions after pre-filtering.\n",
      "  3 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '36'\n",
      "  Extracted 1 text blocks.\n",
      "Processing Page 29 via Image Regions...\n",
      "  Found 7 initial contours.\n",
      "  Created 7 initial regions after pre-filtering.\n",
      "  7 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '37'\n",
      "  Extracted 4 text blocks.\n",
      "Processing Page 30 via Image Regions...\n",
      "  Found 54 initial contours.\n",
      "  Created 54 initial regions after pre-filtering.\n",
      "  7 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '38'\n",
      "  Extracted 5 text blocks.\n",
      "Processing Page 31 via Image Regions...\n",
      "  Found 5 initial contours.\n",
      "  Created 5 initial regions after pre-filtering.\n",
      "  5 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '39'\n",
      "  Extracted 4 text blocks.\n",
      "Processing Page 32 via Image Regions...\n",
      "  Found 6 initial contours.\n",
      "  Created 6 initial regions after pre-filtering.\n",
      "  6 regions remaining after merging and size filtering.\n",
      "  Extracted 2 text blocks.\n",
      "Processing Page 33 via Image Regions...\n",
      "  Found 3 initial contours.\n",
      "  Created 3 initial regions after pre-filtering.\n",
      "  3 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '41'\n",
      "  Extracted 1 text blocks.\n",
      "Processing Page 34 via Image Regions...\n",
      "  Found 3 initial contours.\n",
      "  Created 3 initial regions after pre-filtering.\n",
      "  3 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '42'\n",
      "  Extracted 1 text blocks.\n",
      "Processing Page 35 via Image Regions...\n",
      "  Found 2 initial contours.\n",
      "  Created 2 initial regions after pre-filtering.\n",
      "  2 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '43'\n",
      "  Extracted 0 text blocks.\n",
      "Processing Page 36 via Image Regions...\n",
      "  Found 6 initial contours.\n",
      "  Created 6 initial regions after pre-filtering.\n",
      "  6 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '44'\n",
      "  Extracted 5 text blocks.\n",
      "Processing Page 37 via Image Regions...\n",
      "  Found 5 initial contours.\n",
      "  Created 5 initial regions after pre-filtering.\n",
      "  5 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '45'\n",
      "  Extracted 4 text blocks.\n",
      "Processing Page 38 via Image Regions...\n",
      "  Found 17 initial contours.\n",
      "  Created 17 initial regions after pre-filtering.\n",
      "  7 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '46'\n",
      "  Extracted 3 text blocks.\n",
      "Processing Page 39 via Image Regions...\n",
      "  Found 7 initial contours.\n",
      "  Created 7 initial regions after pre-filtering.\n",
      "  5 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '47'\n",
      "  Extracted 2 text blocks.\n",
      "Processing Page 40 via Image Regions...\n",
      "  Found 5 initial contours.\n",
      "  Created 5 initial regions after pre-filtering.\n",
      "  5 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '48'\n",
      "  Extracted 4 text blocks.\n",
      "Processing Page 41 via Image Regions...\n",
      "  Found 383 initial contours.\n",
      "  Created 383 initial regions after pre-filtering.\n",
      "  4 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '49'\n",
      "  Extracted 3 text blocks.\n",
      "Processing Page 42 via Image Regions...\n",
      "  Found 4 initial contours.\n",
      "  Created 4 initial regions after pre-filtering.\n",
      "  4 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '50'\n",
      "  Extracted 2 text blocks.\n",
      "Processing Page 43 via Image Regions...\n",
      "  Found 7 initial contours.\n",
      "  Created 7 initial regions after pre-filtering.\n",
      "  7 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '51'\n",
      "  Extracted 6 text blocks.\n",
      "Processing Page 44 via Image Regions...\n",
      "  Found 2 initial contours.\n",
      "  Created 2 initial regions after pre-filtering.\n",
      "  2 regions remaining after merging and size filtering.\n",
      "  Extracted 1 text blocks.\n",
      "Processing Page 45 via Image Regions...\n",
      "  Found 1 initial contours.\n",
      "  Created 1 initial regions after pre-filtering.\n",
      "  1 regions remaining after merging and size filtering.\n",
      "  No text words found on page 45 by PyMuPDF.\n",
      "Processing Page 46 via Image Regions...\n",
      "  Found 202 initial contours.\n",
      "  Created 202 initial regions after pre-filtering.\n",
      "  6 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '54'\n",
      "  Extracted 5 text blocks.\n",
      "Processing Page 47 via Image Regions...\n",
      "  Found 74 initial contours.\n",
      "  Created 74 initial regions after pre-filtering.\n",
      "  6 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '55'\n",
      "  Extracted 5 text blocks.\n",
      "Processing Page 48 via Image Regions...\n",
      "  Found 1 initial contours.\n",
      "  Created 1 initial regions after pre-filtering.\n",
      "  1 regions remaining after merging and size filtering.\n",
      "  No text words found on page 48 by PyMuPDF.\n",
      "Processing Page 49 via Image Regions...\n",
      "  Found 1 initial contours.\n",
      "  Created 1 initial regions after pre-filtering.\n",
      "  1 regions remaining after merging and size filtering.\n",
      "  No text words found on page 49 by PyMuPDF.\n",
      "Processing Page 50 via Image Regions...\n",
      "  Found 5 initial contours.\n",
      "  Created 5 initial regions after pre-filtering.\n",
      "  5 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '58'\n",
      "  Extracted 3 text blocks.\n",
      "Processing Page 51 via Image Regions...\n",
      "  Found 7 initial contours.\n",
      "  Created 7 initial regions after pre-filtering.\n",
      "  7 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '59'\n",
      "  Extracted 6 text blocks.\n",
      "Processing Page 52 via Image Regions...\n",
      "  Found 6 initial contours.\n",
      "  Created 6 initial regions after pre-filtering.\n",
      "  6 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '60'\n",
      "  Extracted 3 text blocks.\n",
      "Processing Page 53 via Image Regions...\n",
      "  Found 8 initial contours.\n",
      "  Created 8 initial regions after pre-filtering.\n",
      "  8 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '61'\n",
      "  Extracted 5 text blocks.\n",
      "Processing Page 54 via Image Regions...\n",
      "  Found 364 initial contours.\n",
      "  Created 364 initial regions after pre-filtering.\n",
      "  4 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '62'\n",
      "  Extracted 3 text blocks.\n",
      "Processing Page 55 via Image Regions...\n",
      "  Found 7 initial contours.\n",
      "  Created 7 initial regions after pre-filtering.\n",
      "  7 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '63'\n",
      "  Extracted 6 text blocks.\n",
      "Processing Page 56 via Image Regions...\n",
      "  Found 5 initial contours.\n",
      "  Created 5 initial regions after pre-filtering.\n",
      "  5 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '64'\n",
      "  Extracted 3 text blocks.\n",
      "Processing Page 57 via Image Regions...\n",
      "  Found 7 initial contours.\n",
      "  Created 7 initial regions after pre-filtering.\n",
      "  7 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '65'\n",
      "  Extracted 6 text blocks.\n",
      "Processing Page 58 via Image Regions...\n",
      "  Found 3 initial contours.\n",
      "  Created 3 initial regions after pre-filtering.\n",
      "  3 regions remaining after merging and size filtering.\n",
      "  Skipping numeric block: '66'\n",
      "  Extracted 2 text blocks.\n",
      "Finished extraction. Total elements: 241\n",
      "Identifying potential watermarks...\n",
      "  Identified potential watermarks (4 unique texts): {('Chapter 3', 9.0), ('Clinical Knowledge', 9.0), ('Legends of Photography', 9.0), ('Chapter 2', 9.0)}\n",
      "  Removed 42 watermark instances. Elements remaining: 199\n",
      "Sorting all elements for hierarchical processing...\n",
      "Sorting complete.\n",
      "Calculating hierarchy markers (child spans) based on text height...\n",
      "Finished calculating child spans.\n",
      "Building hierarchy tree...\n",
      "  Identified 73 potential root nodes (chapters/sections).\n",
      "Generating JSON output...\n",
      "Finished generating JSON structure with 4 top-level items.\n",
      "Saving structured JSON to: D:\\DATA300\\AudioBookSum\\pdf\\Didi Huberman_structured.json\n",
      "Successfully saved JSON.\n",
      "--- Processing finished in 2.96 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "DUMMY_NODE_HEIGHT = 1000\n",
    "\n",
    "def extract_and_prepare_elements(pdf_path):\n",
    "    \"\"\"\n",
    "    Opens PDF, extracts text elements using the provided function,\n",
    "    ensures required keys are present, sorts by reading order per page,\n",
    "    and returns a single list of all elements.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = pymupdf.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening PDF {pdf_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "    all_elements = []\n",
    "    num_pages = len(doc)\n",
    "    print(f\"Processing {num_pages} pages from {os.path.basename(pdf_path)}...\")\n",
    "\n",
    "    for i in range(num_pages):\n",
    "        try:\n",
    "            # Call the external extraction function (abstracted)\n",
    "            page_elements = extract_page_text_via_image_regions(page=doc[i], visual_proof=False)\n",
    "\n",
    "            # Validate and potentially enrich elements\n",
    "            valid_page_elements = []\n",
    "            for element in page_elements:\n",
    "                 # Ensure essential keys exist (add defaults or skip if necessary)\n",
    "                if not all(k in element for k in [\"content\", \"occupy_space\", \"text_height_median\"]):\n",
    "                     print(f\"    Warning: Skipping element on page {i+1} due to missing keys: {element.get('content', '[No Content]')[:50]}...\")\n",
    "                     continue\n",
    "                element['page_num'] = i # Ensure correct page number is set\n",
    "                valid_page_elements.append(element)\n",
    "\n",
    "\n",
    "            # Sort elements on the current page by position (reading order)\n",
    "            valid_page_elements.sort(key=lambda x: (x[\"occupy_space\"].y0, x[\"occupy_space\"].x0))\n",
    "            all_elements.extend(valid_page_elements)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing page {i + 1}: {e}\")\n",
    "            # Decide whether to continue or stop on page error\n",
    "            continue\n",
    "\n",
    "    print(f\"Finished extraction. Total elements: {len(all_elements)}\")\n",
    "    doc.close() # Ensure the document is closed\n",
    "    return all_elements\n",
    "\n",
    "\n",
    "def identify_and_filter_watermarks(elements):\n",
    "    \"\"\"\n",
    "    Identifies elements with identical stripped content appearing more than once\n",
    "    and filters them out.\n",
    "    \"\"\"\n",
    "    if not elements:\n",
    "        return [], set()\n",
    "\n",
    "    print(\"Identifying potential watermarks...\")\n",
    "    # Count occurrences of each unique stripped text content\n",
    "    text_counts = collections.Counter(\n",
    "        (el[\"content\"].strip(), el.get(\"text_height_median\", 0)) for el in elements if el.get(\"content\")\n",
    "    )\n",
    "    # TODO: Factor in median text height\n",
    "    # Identify texts that appear more than once as potential watermarks\n",
    "    watermark_candidates = {(text[0], text[1]) for text, count in text_counts.items() if count > 1 and text} \n",
    "\n",
    "    if watermark_candidates:\n",
    "        print(f\"  Identified potential watermarks ({len(watermark_candidates)} unique texts): {watermark_candidates}\")\n",
    "        # Filter out elements whose stripped content is in the watermark set\n",
    "        filtered_elements = [\n",
    "            el for el in elements\n",
    "            if el.get(\"content\") and (el[\"content\"].strip(), el[\"text_height_median\"]) not in watermark_candidates\n",
    "        ]\n",
    "        print(f\"  Removed {len(elements) - len(filtered_elements)} watermark instances. Elements remaining: {len(filtered_elements)}\")\n",
    "        return filtered_elements, watermark_candidates\n",
    "    else:\n",
    "        print(\"  No potential watermarks found.\")\n",
    "        return elements, set()\n",
    "\n",
    "\n",
    "def calculate_child_spans(elements):\n",
    "    \"\"\"\n",
    "    Calculates the 'span' for each element, representing how many subsequent,\n",
    "    smaller-height elements fall under it before encountering an element of\n",
    "    equal or greater height. This is used to determine parent-child relationships.\n",
    "\n",
    "    Uses a stack-based approach to find the \"next greater or equal element\" boundary.\n",
    "    \"\"\"\n",
    "    if not elements:\n",
    "        return []\n",
    "\n",
    "    print(\"Calculating hierarchy markers (child spans) based on text height...\")\n",
    "    # Add a dummy element at the end with a very large height.\n",
    "    # This ensures all elements in the stack are processed correctly without needing extra end-of-loop logic.\n",
    "    try:\n",
    "        dummy_element = elements[-1].copy() if elements else {} # Handle empty list case\n",
    "        dummy_element[\"text_height_median\"] = DUMMY_NODE_HEIGHT\n",
    "    except KeyError:\n",
    "         print(\"Error: Last element missing 'text_height_median'. Cannot create dummy node reliably.\")\n",
    "         # Fallback or raise error - using arbitrary large height if copy fails but list not empty\n",
    "         dummy_element = {\"text_height_median\": DUMMY_NODE_HEIGHT} if elements else {}\n",
    "\n",
    "\n",
    "    processing_list = elements + [dummy_element]\n",
    "    num_processing = len(processing_list)\n",
    "    # Stores how many elements immediately following element `i` are 'under' it (smaller height).\n",
    "    child_span_counts = [0] * num_processing\n",
    "    stack = [] # Stores indices of elements waiting for their scope boundary (next >= element)\n",
    "\n",
    "    for idx, current_element in enumerate(processing_list):\n",
    "        current_height = current_element.get(\"text_height_median\", 0) # Default height if missing\n",
    "\n",
    "        # While stack is not empty AND current element's height is >= stack top element's height:\n",
    "        # The current element marks the end of the scope for the element at the top of the stack.\n",
    "        while stack and current_height >= processing_list[stack[-1]].get(\"text_height_median\", 0):\n",
    "            parent_index = stack.pop()\n",
    "            # Calculate the span: number of elements between parent and current element\n",
    "            child_span_counts[parent_index] = idx - parent_index - 1\n",
    "\n",
    "        # Push the index of the current element onto the stack\n",
    "        stack.append(idx)\n",
    "\n",
    "    print(\"Finished calculating child spans.\")\n",
    "    return child_span_counts[:-1]\n",
    "\n",
    "\n",
    "def build_hierarchy(elements, child_span_counts):\n",
    "    \"\"\"\n",
    "    Builds a tree structure using Node objects based on the elements and their\n",
    "    calculated child spans. Identifies root nodes (potential chapters/sections).\n",
    "    \"\"\"\n",
    "    if not elements or len(elements) != len(child_span_counts):\n",
    "        print(\"Warning: Mismatch between elements and child spans, or list is empty. Cannot build hierarchy.\")\n",
    "        return [], [] \n",
    "\n",
    "    print(\"Building hierarchy tree...\")\n",
    "    nodes = [Node(el) for el in elements]\n",
    "    num_nodes = len(nodes)\n",
    "\n",
    "    for i in range(num_nodes):\n",
    "        span = child_span_counts[i]\n",
    "        if span > 0:\n",
    "            # This node `i` is a parent. Add its direct children.\n",
    "            current_child_idx = i + 1\n",
    "            while current_child_idx < min(i + 1 + span, num_nodes):\n",
    "                # Add node at `current_child_idx` as a child of node `i`\n",
    "                nodes[i].add_child(nodes[current_child_idx])\n",
    "                grandchild_span = child_span_counts[current_child_idx]\n",
    "                current_child_idx += (grandchild_span + 1) # Move past the child and its descendants\n",
    "\n",
    "    # Identify root nodes: typically nodes that have children (parents).\n",
    "    root_nodes = [node for i, node in enumerate(nodes) if child_span_counts[i] > 0]\n",
    "\n",
    "    # Fallback: If no nodes have children (e.g., flat structure or all same height),\n",
    "    # treat all original nodes as roots (potentially filtered later if needed).\n",
    "    if not root_nodes and nodes:\n",
    "        print(\"  Warning: No parent nodes identified based on height/span. Assuming flat structure or single level.\")\n",
    "        # Decide strategy: either all nodes are roots, or maybe just the first?\n",
    "        # Original code implies all nodes become roots in this case if `sum(count_till_match_size) == 0`.\n",
    "        # Let's check the span sum for that condition.\n",
    "        if sum(child_span_counts) == 0:\n",
    "             root_nodes = nodes\n",
    "        else:\n",
    "             # This case (nodes exist, spans exist, but no nodes selected as roots) seems unlikely with the logic.\n",
    "             # If it happens, maybe select the first node or log an error.\n",
    "             print(\"  Ambiguous root node condition. Defaulting to all nodes as roots.\")\n",
    "             root_nodes = nodes\n",
    "\n",
    "    elif not nodes:\n",
    "        print(\"  No text elements to form a hierarchy.\")\n",
    "        root_nodes = []\n",
    "    else:\n",
    "        print(f\"  Identified {len(root_nodes)} potential root nodes (chapters/sections).\")\n",
    "\n",
    "    return nodes, root_nodes # Return all nodes and the identified roots\n",
    "\n",
    "\n",
    "def generate_json_structure(root_nodes):\n",
    "    \"\"\"\n",
    "    Generates a nested list of dictionaries (JSON structure) from the root nodes\n",
    "    using Breadth-First Search (BFS) to traverse the hierarchy.\n",
    "    \"\"\"\n",
    "    if not root_nodes:\n",
    "        return []\n",
    "\n",
    "    print(\"Generating JSON output...\")\n",
    "    output_json_list = []\n",
    "    # Keep track of nodes already added to the JSON globally to handle\n",
    "    # cases where the root detection might be imperfect or graphs are disconnected.\n",
    "    visited_nodes = set()\n",
    "\n",
    "    def bfs_to_dict(start_node):\n",
    "        \"\"\"Performs BFS from a node and builds the nested dictionary for its branch.\"\"\"\n",
    "        # Check if this node was already processed as part of another root's tree\n",
    "        if start_node in visited_nodes:\n",
    "            return None # Don't process this branch again\n",
    "\n",
    "        # Use a queue for BFS: stores tuples of (node_to_process, dict_to_populate_for_that_node)\n",
    "        # Initialize with the starting node and the dictionary that will represent it\n",
    "        root_dict = {}\n",
    "        queue = collections.deque([(start_node, root_dict)])\n",
    "        # Keep track of nodes visited *within this specific BFS call* to prevent cycles within a component\n",
    "        local_visited = {start_node}\n",
    "\n",
    "        while queue:\n",
    "            current_node, current_data_dict = queue.popleft()\n",
    "\n",
    "            # Mark node as globally visited *after* processing its data\n",
    "            visited_nodes.add(current_node)\n",
    "\n",
    "            # Populate the dictionary for the current node\n",
    "            content_text = current_node.content.get(\"content\", \"\")\n",
    "            current_data_dict.update({\n",
    "                \"name\": content_text.strip(),\n",
    "                \"children\": []\n",
    "                })\n",
    "\n",
    "            # Prepare children list and add valid children to the queue\n",
    "            child_list = current_data_dict[\"children\"]\n",
    "            for child_node in current_node.children:\n",
    "                # Process child only if not visited globally or within this BFS call\n",
    "                if child_node not in visited_nodes and child_node not in local_visited:\n",
    "                    local_visited.add(child_node)\n",
    "                    child_data = {} # Create a new dict for the child\n",
    "                    child_list.append(child_data) # Add the placeholder dict to parent's children list\n",
    "                    queue.append((child_node, child_data)) # Add child node and its dict to the queue\n",
    "\n",
    "        return root_dict # Return the populated dictionary for the starting node's branch\n",
    "\n",
    "    # Iterate through the identified root nodes\n",
    "    for root in root_nodes:\n",
    "        branch_dict = bfs_to_dict(root)\n",
    "        if branch_dict: # Only add if the BFS generated a structure (i.e., node wasn't already visited)\n",
    "            output_json_list.append(branch_dict)\n",
    "\n",
    "    print(f\"Finished generating JSON structure with {len(output_json_list)} top-level items.\")\n",
    "    return output_json_list\n",
    "\n",
    "\n",
    "def save_to_json(data, output_path):\n",
    "    \"\"\"Saves the provided data structure to a JSON file.\"\"\"\n",
    "    print(f\"Saving structured JSON to: {output_path}\")\n",
    "    try:\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        print(\"Successfully saved JSON.\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error writing JSON file to {output_path}: {e}\")\n",
    "    except TypeError as e:\n",
    "        print(f\"Error serializing data to JSON (check data structure): {e}\")\n",
    "\n",
    "\n",
    "# --- Main Processing Function ---\n",
    "\n",
    "def process_pdf_to_structured_json(input_pdf_path, output_json_path=None):\n",
    "    \"\"\"\n",
    "    Main orchestrator function:\n",
    "    1. Checks input path.\n",
    "    2. Extracts and prepares text elements.\n",
    "    3. Identifies and filters watermarks.\n",
    "    4. Sorts elements globally for hierarchy processing.\n",
    "    5. Calculates child spans based on height.\n",
    "    6. Builds the node hierarchy.\n",
    "    7. Generates the final JSON structure.\n",
    "    8. Saves the JSON file.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n--- Starting processing for: {input_pdf_path} ---\")\n",
    "\n",
    "    if not os.path.exists(input_pdf_path):\n",
    "        print(f\"Error: Input PDF not found at {input_pdf_path}\")\n",
    "        return\n",
    "\n",
    "    if output_json_path is None:\n",
    "        output_json_path = os.path.splitext(input_pdf_path)[0] + \"_structured.json\"\n",
    "\n",
    "    # 1. Extract and Prepare Elements (Abstracted Call)\n",
    "    #    CRITICAL: Requires extract_text_with_ocr_approach to return dicts with\n",
    "    #    'content', 'occupy_space' (Rect-like), 'text_height_median', 'page_num'.\n",
    "    elements = extract_and_prepare_elements(input_pdf_path)\n",
    "    if not elements:\n",
    "        print(\"No text elements extracted or processed. Aborting.\")\n",
    "        return\n",
    "\n",
    "    # 2. Identify and Filter Watermarks\n",
    "    elements, _ = identify_and_filter_watermarks(elements) # Watermark list ignored for now\n",
    "    if not elements:\n",
    "        print(\"No content remaining after watermark removal. Aborting.\")\n",
    "        return\n",
    "\n",
    "    # 3. Sort All Elements Globally for Hierarchy Building\n",
    "    #    Sort primarily by page, then y-position (top-to-bottom), then x-position (left-to-right).\n",
    "    print(\"Sorting all elements for hierarchical processing...\")\n",
    "    elements.sort(key=lambda x: (\n",
    "        x.get(\"page_num\", 0),\n",
    "        x.get(\"occupy_space\").y0 if x.get(\"occupy_space\") else 0,\n",
    "        x.get(\"occupy_space\").x0 if x.get(\"occupy_space\") else 0\n",
    "    ))\n",
    "    print(\"Sorting complete.\")\n",
    "\n",
    "    # 4. Calculate Hierarchy Markers (Child Spans)\n",
    "    child_span_counts = calculate_child_spans(elements)\n",
    "\n",
    "    # 5. Build Hierarchy Tree\n",
    "    all_nodes, root_nodes = build_hierarchy(elements, child_span_counts)\n",
    "    if not root_nodes:\n",
    "         print(\"No hierarchical structure could be determined. Aborting JSON generation.\")\n",
    "         # Optionally, could still output a flat list here if desired.\n",
    "         return\n",
    "\n",
    "    # 6. Generate JSON Output from Tree Roots\n",
    "    output_data = generate_json_structure(root_nodes)\n",
    "\n",
    "    # 7. Save the JSON Output\n",
    "    save_to_json(output_data, output_json_path)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"--- Processing finished in {end_time - start_time:.2f} seconds ---\")\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_to_process =r\"D:\\DATA300\\AudioBookSum\\pdf\\Didi Huberman.pdf\"\n",
    "    \n",
    "    # Check if the placeholder path is still set\n",
    "    if pdf_to_process == \"path/to/your/document.pdf\":\n",
    "        print(\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(\"!!! Please update the 'pdf_to_process' variable in the   !!!\")\n",
    "        print(\"!!! '__main__' block of the script before running.        !!!\")\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")\n",
    "    elif not os.path.exists(pdf_to_process):\n",
    "         print(f\"\\nWarning: The specified PDF file does not exist: {pdf_to_process}\")\n",
    "         print(\"Script will not run processing.\")\n",
    "    else:\n",
    "        # Run the main processing pipeline\n",
    "        process_pdf_to_structured_json(pdf_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 203 ms\n",
      "Wall time: 219 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_pdf_path = r\"D:\\DATA300\\AudioBookSum\\pdf\\Didi Huberman.pdf\"\n",
    "words, extract_method = extract_text(input_pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.73 s\n",
      "Wall time: 3.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_pdf_path = r\"D:\\DATA300\\AudioBookSum\\pdf\\Didi Huberman.pdf\"\n",
    "doc = pymupdf.open(input_pdf_path)\n",
    "text = \"\"\n",
    "median_collection = []\n",
    "content = []\n",
    "\n",
    "for i in range(len(doc)):\n",
    "    extracted_pages = sorted(extract_text_with_ocr_approach(input_pdf_path, page_num =i, visual_proof=False), \\\n",
    "        key = lambda x: [x[\"occupy_space\"].y0, x[\"occupy_space\"].x0])\n",
    "    content.extend(extracted_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_text(text_blocks, chunk_size=1000, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    Chunk text blocks into smaller pieces while preserving page and bounding box information.\n",
    "    \n",
    "    Args:\n",
    "        text_blocks (list): List of dictionaries containing text with metadata (page, bbox, etc.)\n",
    "        chunk_size (int): Maximum size of each chunk in characters\n",
    "        chunk_overlap (int): Number of overlapping characters between chunks\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries containing chunks with preserved metadata\n",
    "    \"\"\"\n",
    "    chunked_data = []  \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "    )\n",
    "    \n",
    "    # First combine all text blocks into a single document string for chunking\n",
    "    combined_text = \"\"\n",
    "    metadata_map = {}  # Map character positions to original metadata\n",
    "    current_position = 0\n",
    "    \n",
    "    # Process each text block and map character positions to metadata\n",
    "    for idx, block in enumerate(text_blocks):\n",
    "        # Get text and metadata\n",
    "        text = block.get(\"content\", \"\")\n",
    "        if not text:\n",
    "            continue\n",
    "            \n",
    "        block_length = len(text)\n",
    "        page = block.get(\"page_num\", 0)\n",
    "        bbox = block.get(\"occupy_space\", None)\n",
    "        text_height = block.get(\"text_height_median\", None)\n",
    "        \n",
    "        # Map each character position in the combined text to its source metadata\n",
    "        for i in range(current_position, current_position + block_length):\n",
    "            metadata_map[i] = {\n",
    "                \"page\": page,\n",
    "                \"bbox\": bbox,\n",
    "                \"text_height\": text_height,\n",
    "                \"original_block_index\": idx\n",
    "            }\n",
    "        \n",
    "        # Add text to combined string with a marker between blocks\n",
    "        combined_text += text + \" [BLOCK_BREAK] \"\n",
    "        current_position += block_length + len(\" [BLOCK_BREAK] \")\n",
    "    \n",
    "    # Split the combined text into chunks\n",
    "    chunks = text_splitter.split_text(combined_text)\n",
    "    \n",
    "    # For each chunk, determine the predominant page and bounding box\n",
    "    chunk_start = 0\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Find the start position of this chunk in the combined text\n",
    "        if i == 0:\n",
    "            start_pos = 0\n",
    "        else:\n",
    "            # Look for chunk in the vicinity of where we expect it\n",
    "            search_start = max(0, chunk_start - chunk_overlap)\n",
    "            search_text = combined_text[search_start:search_start + len(chunk) + 100]\n",
    "            rel_pos = search_text.find(chunk[:50])  # Use prefix to locate chunk\n",
    "            if rel_pos != -1:\n",
    "                start_pos = search_start + rel_pos\n",
    "            else:\n",
    "                # Fallback if exact match not found\n",
    "                start_pos = chunk_start\n",
    "        \n",
    "        # Update for next iteration\n",
    "        chunk_start = start_pos + len(chunk) - chunk_overlap\n",
    "            \n",
    "       \n",
    "        page_counts = {}\n",
    "        bbox_by_page = {}\n",
    "        \n",
    "        for j in range(start_pos, min(start_pos + len(chunk), len(combined_text))):\n",
    "            if j in metadata_map:\n",
    "                page = metadata_map[j][\"page\"]\n",
    "                if page not in page_counts:\n",
    "                    page_counts[page] = 0\n",
    "                    bbox_by_page[page] = []\n",
    "                    \n",
    "                page_counts[page] += 1\n",
    "                if metadata_map[j][\"bbox\"] and metadata_map[j][\"bbox\"] not in bbox_by_page[page]:\n",
    "                    bbox_by_page[page].append(metadata_map[j][\"bbox\"])\n",
    "        \n",
    "        # Find predominant page\n",
    "        predominant_page = max(page_counts.items(), key=lambda x: x[1])[0] if page_counts else 0\n",
    "        \n",
    "        # Create enhanced chunk with metadata\n",
    "        enhanced_chunk = {\n",
    "            \"text\": chunk.replace(\" [BLOCK_BREAK] \", \"\\n\\n\"),\n",
    "            \"page\": predominant_page,\n",
    "            \"bbox_list\": bbox_by_page.get(predominant_page, []),\n",
    "            \"start_position\": start_pos,\n",
    "            \"chunk_index\": i\n",
    "        }\n",
    "        \n",
    "        chunked_data.append(enhanced_chunk)\n",
    "    \n",
    "    return chunked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_interesting_points(chunked_data, llm, text_blocks, file_name, threshold=5):\n",
    "    \"\"\"\n",
    "    Identify important points in text using LLM, adapted to work with chunk_text output.\n",
    "    \n",
    "    Args:\n",
    "        chunked_data (list): List of dictionaries returned by chunk_text function\n",
    "        llm: LLM model for generating interesting points\n",
    "        text_blocks (list): Original text blocks with metadata\n",
    "        file_name (str): Path to cache file\n",
    "        threshold (int): Minimum word count for segments to be considered\n",
    "        \n",
    "    Returns:\n",
    "        list: List of interesting sections with metadata and page annotations\n",
    "    \"\"\"\n",
    "    interesting_sections = []\n",
    "    \n",
    "    # Return early if chunked_data is empty\n",
    "    if not chunked_data:\n",
    "        print(\"No content identified in the document\")\n",
    "        return interesting_sections\n",
    "    \n",
    "    # Create block index for faster lookup - map page numbers to blocks on that page\n",
    "    page_to_blocks = defaultdict(list)\n",
    "    for block in text_blocks:\n",
    "        # Pre-normalize block text once\n",
    "        content = block.get(\"content\", \"\")\n",
    "        if content:\n",
    "            block[\"norm_text\"] = ' '.join(content.split())\n",
    "            page_to_blocks[block.get(\"page_num\", 0)].append(block)\n",
    "    \n",
    "    # Function to find matching block for a segment with improved fuzzy matching\n",
    "    def find_matching_block(segment, page_hint=None):\n",
    "        print(f\"Finding matching block for: {segment[:50]} ...\") \n",
    "        print(f\"Page hint: {page_hint}\")\n",
    "        norm_segment = ' '.join(segment.split())\n",
    "        if not norm_segment:\n",
    "            return None, False\n",
    "            \n",
    "        # First try exact page if provided\n",
    "        if page_hint is not None:\n",
    "            for block in page_to_blocks.get(page_hint, []):\n",
    "                if norm_segment in block[\"norm_text\"]:\n",
    "                    return block, True\n",
    "        \n",
    "        # Try exact matching across all pages\n",
    "        for page, page_blocks in page_to_blocks.items():\n",
    "            for block in page_blocks:\n",
    "                if norm_segment in block[\"norm_text\"]:\n",
    "                    return block, True\n",
    "        \n",
    "        # Try finding any substantial overlap\n",
    "        best_match = None\n",
    "        highest_similarity = 0.6  # Lowered threshold for better recall\n",
    "        best_overlap_len = 0\n",
    "        \n",
    "        # First prioritize matches by page if available\n",
    "        if page_hint is not None:\n",
    "            for block in page_to_blocks.get(page_hint, []):\n",
    "                # Try SequenceMatcher similarity\n",
    "                similarity = difflib.SequenceMatcher(None, norm_segment, block[\"norm_text\"]).ratio()\n",
    "                if similarity > highest_similarity:\n",
    "                    highest_similarity = similarity\n",
    "                    best_match = block\n",
    "                \n",
    "                # Try finding common substring\n",
    "                common_words = set(norm_segment.split()) & set(block[\"norm_text\"].split())\n",
    "                if len(common_words) > best_overlap_len:\n",
    "                    best_overlap_len = len(common_words)\n",
    "                    if not best_match:  # Only replace if we don't have a high similarity match\n",
    "                        best_match = block\n",
    "        \n",
    "        # If no good match on the hinted page, try all pages\n",
    "        if not best_match or highest_similarity < 0.7:\n",
    "            for page, page_blocks in page_to_blocks.items():\n",
    "                for block in page_blocks:\n",
    "                    similarity = difflib.SequenceMatcher(None, norm_segment, block[\"norm_text\"]).ratio()\n",
    "                    if similarity > highest_similarity:\n",
    "                        highest_similarity = similarity\n",
    "                        best_match = block\n",
    "                    \n",
    "                    # Try finding common substring as backup approach\n",
    "                    common_words = set(norm_segment.split()) & set(block[\"norm_text\"].split())\n",
    "                    overlap_ratio = len(common_words) / max(1, len(norm_segment.split()))\n",
    "                    if overlap_ratio > 0.5 and len(common_words) > best_overlap_len:\n",
    "                        best_overlap_len = len(common_words)\n",
    "                        if highest_similarity < 0.7:  # Only use word overlap if similarity isn't high\n",
    "                            best_match = block\n",
    "        \n",
    "        # If still no match, but we have a page hint, return any block from that page\n",
    "        if not best_match and page_hint is not None and page_hint in page_to_blocks and page_to_blocks[page_hint]:\n",
    "            return page_to_blocks[page_hint][0], False\n",
    "            \n",
    "        # If still no match, return any block from any page as last resort\n",
    "        if not best_match and page_to_blocks:\n",
    "            first_page = min(page_to_blocks.keys())\n",
    "            if page_to_blocks[first_page]:\n",
    "                return page_to_blocks[first_page][0], False\n",
    "        \n",
    "        return best_match, False\n",
    "    \n",
    "    # Function to extract page number from text with [Page X] annotation\n",
    "    def extract_page_number(text):\n",
    "        page_match = re.search(r'\\[Page (\\d+)\\]', text)\n",
    "        if page_match:\n",
    "            return int(page_match.group(1)) - 1  # Convert to 0-indexed\n",
    "        return None\n",
    "    \n",
    "    # Cache handling using structured JSON format\n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            print(f\"Loading cached interesting points from {file_name}\")\n",
    "            # Try JSON format first (for files created by the optimized version)\n",
    "            try:\n",
    "                with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "                    cached_data = json.load(f)\n",
    "                    \n",
    "                for segment_data in cached_data.get(\"segments\", []):\n",
    "                    segment = segment_data.get(\"text\", \"\")\n",
    "                    page_hint = segment_data.get(\"page\")\n",
    "                    \n",
    "                    if len(segment.split()) < threshold:\n",
    "                        continue\n",
    "                    \n",
    "                    # Check for page number in the text itself\n",
    "                    text_page = extract_page_number(segment)\n",
    "                    if text_page is not None:\n",
    "                        page_hint = text_page\n",
    "                        # Remove the page annotation if it exists\n",
    "                        segment_for_matching = re.sub(r'\\[Page \\d+\\]\\s*', '', segment).strip()\n",
    "                    else:\n",
    "                        segment_for_matching = segment\n",
    "                    \n",
    "                    matched_block, exact_match = find_matching_block(segment_for_matching, page_hint)\n",
    "                    if matched_block:\n",
    "                        # Add page annotation to the text\n",
    "                        page_num = matched_block.get(\"page_num\", 0)\n",
    "                        page_annotation = f\"[Page {page_num+1}]\"\n",
    "                        \n",
    "                        # Keep original text but ensure page annotation is correct\n",
    "                        if text_page is None:\n",
    "                            clean_segment = segment_for_matching\n",
    "                            display_text = f\"{page_annotation} {clean_segment}\"\n",
    "                        elif text_page != page_num:\n",
    "                            # Replace with correct page\n",
    "                            clean_segment = re.sub(r'\\[Page \\d+\\]\\s*', '', segment).strip()\n",
    "                            display_text = f\"{page_annotation} {clean_segment}\"\n",
    "                        else:\n",
    "                            display_text = segment  # Keep original if page is correct\n",
    "                        \n",
    "                        interesting_sections.append({\n",
    "                            \"page\": page_num,\n",
    "                            \"text\": display_text,\n",
    "                            \"category\": \"main\",\n",
    "                            \"bbox\": matched_block.get(\"occupy_space\"),\n",
    "                            \"page_text\": f\"Page {page_num+1}\"\n",
    "                        })\n",
    "                    else:\n",
    "                        # Still keep the segment but with a default page\n",
    "                        default_page = page_hint if page_hint is not None else 0\n",
    "                        page_annotation = f\"[Page {default_page+1}]\"\n",
    "                        \n",
    "                        # Handle page annotation in text\n",
    "                        if text_page is None:\n",
    "                            display_text = f\"{page_annotation} {segment}\"\n",
    "                        else:\n",
    "                            # Keep original annotation\n",
    "                            display_text = segment\n",
    "                        \n",
    "                        print(f\"Using default page for unmatched segment: {segment[:50]}...\")\n",
    "                        interesting_sections.append({\n",
    "                            \"page\": default_page,\n",
    "                            \"text\": display_text,\n",
    "                            \"category\": \"main\",\n",
    "                            \"bbox\": None,\n",
    "                            \"page_text\": f\"Page {default_page+1}\"\n",
    "                        })\n",
    "                \n",
    "            except json.JSONDecodeError:\n",
    "                # Fall back to the legacy format for backward compatibility\n",
    "                with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "                    content = f.read()\n",
    "                \n",
    "                cached_segments = re.findall(r'```segment(?:\\s*-\\s*(\\d+))?\\s*(.*?)```', content, re.DOTALL)\n",
    "                \n",
    "                for page_num_str, segment in cached_segments:\n",
    "                    segment = segment.strip()\n",
    "                    if len(segment.split()) < threshold:\n",
    "                        continue\n",
    "                    \n",
    "                    # Try to get page number from the text first\n",
    "                    text_page = extract_page_number(segment)\n",
    "                    if text_page is not None:\n",
    "                        page_hint = text_page\n",
    "                        # Remove the page annotation if it exists\n",
    "                        segment_for_matching = re.sub(r'\\[Page \\d+\\]\\s*', '', segment).strip()\n",
    "                    else:\n",
    "                        page_hint = int(page_num_str) - 1 if page_num_str else None\n",
    "                        segment_for_matching = segment\n",
    "                    \n",
    "                    matched_block, exact_match = find_matching_block(segment_for_matching, page_hint)\n",
    "                    \n",
    "                    if matched_block:\n",
    "                        # Add page annotation to the text\n",
    "                        page_num = matched_block.get(\"page_num\", 0)\n",
    "                        page_annotation = f\"[Page {page_num+1}]\"\n",
    "                        \n",
    "                        # Keep original text but ensure page annotation is correct\n",
    "                        if text_page is None:\n",
    "                            clean_segment = segment_for_matching\n",
    "                            display_text = f\"{page_annotation} {clean_segment}\"\n",
    "                        elif text_page != page_num:\n",
    "                            # Replace with correct page\n",
    "                            clean_segment = re.sub(r'\\[Page \\d+\\]\\s*', '', segment).strip()\n",
    "                            display_text = f\"{page_annotation} {clean_segment}\"\n",
    "                        else:\n",
    "                            display_text = segment  # Keep original if page is correct\n",
    "                        \n",
    "                        interesting_sections.append({\n",
    "                            \"page\": page_num,\n",
    "                            \"text\": display_text,\n",
    "                            \"category\": \"main\",\n",
    "                            \"bbox\": matched_block.get(\"occupy_space\"),\n",
    "                            \"page_text\": f\"Page {page_num+1}\"\n",
    "                        })\n",
    "                    else:\n",
    "                        # Still keep the segment but with a default page\n",
    "                        default_page = page_hint if page_hint is not None else 0\n",
    "                        page_annotation = f\"[Page {default_page+1}]\"\n",
    "                        \n",
    "                        if text_page is None:\n",
    "                            display_text = f\"{page_annotation} {segment}\"\n",
    "                        else:\n",
    "                            # Keep original annotation\n",
    "                            display_text = segment\n",
    "                        \n",
    "                        print(f\"Using default page for unmatched segment: {segment[:50]}...\")\n",
    "                        interesting_sections.append({\n",
    "                            \"page\": default_page,\n",
    "                            \"text\": display_text,\n",
    "                            \"category\": \"main\",\n",
    "                            \"bbox\": None,\n",
    "                            \"page_text\": f\"Page {default_page+1}\"\n",
    "                        })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading cached data: {e}. Generating new segments.\")\n",
    "            interesting_sections = []  # Reset and try generating new\n",
    "    \n",
    "    # Generate new segments if no cached results were loaded\n",
    "    if not interesting_sections:\n",
    "        try:\n",
    "            print(\"Generating new interesting points with LLM...\")\n",
    "            \n",
    "            prompt_template = PromptTemplate(\n",
    "                input_variables=[\"text\"],\n",
    "                template=\"\"\"\n",
    "                You are a reasoning summarizer.\n",
    "                Summarize the provided text and support your summary using different verbatim snippets from the original text.\n",
    "                Remember:\n",
    "                The reasoning section must ONLY contain verbatim text from the document.\n",
    "                Every sentence in the reasoning must be supporting sentences in the summary section.\n",
    "                Do not add any information that isn't directly from the document.\n",
    "                IMPORTANT: Do not remove page annotations like [Page X] from your snippets.\n",
    "                \n",
    "                Format each important snippet as:\n",
    "                ```segment - <page number>\n",
    "                <exact text from the document including the [Page X] annotation>\n",
    "                ```\n",
    "                \n",
    "                Below is text from the main content of a document in English:\n",
    "                {text}\n",
    "                \"\"\"\n",
    "            )\n",
    "            \n",
    "            # Concatenate text from all chunks\n",
    "            all_text = \"\"\n",
    "            for chunk in chunked_data:\n",
    "                page_num = chunk[\"page\"]\n",
    "                all_text += f\"[Page {page_num+1}] {chunk['text']}\\n\\n\"\n",
    "                \n",
    "            prompt = prompt_template.format(text=all_text)\n",
    "            \n",
    "            response = llm.invoke(prompt)\n",
    "            content = response.content\n",
    "            print(\"LLM response received\")\n",
    "            # Extract segments\n",
    "            segments = re.findall(r'```segment(?:\\s*-\\s*(\\d+))?\\s*(.*?)```', content, re.DOTALL)\n",
    "            print(f\"Extracted {len(segments)} segments from LLM response\")\n",
    "            \n",
    "            # Save in structured JSON format for better caching\n",
    "            cached_data = {\"segments\": []}\n",
    "            \n",
    "            for page_num_str, segment_text in segments:\n",
    "                segment = segment_text.strip()\n",
    "                if len(segment.split()) < threshold:\n",
    "                    continue\n",
    "                \n",
    "                # Try to extract page number from the text content first\n",
    "                text_page = extract_page_number(segment)\n",
    "                if text_page is not None:\n",
    "                    page_hint = text_page\n",
    "                    print(f\"Found page annotation in text: Page {page_hint+1}\")\n",
    "                    # Remove page annotation for matching but keep original text\n",
    "                    segment_for_matching = re.sub(r'\\[Page \\d+\\]\\s*', '', segment).strip()\n",
    "                else:\n",
    "                    page_hint = int(page_num_str) - 1 if page_num_str else None\n",
    "                    print(f\"Using segment marker page: Page {page_hint+1 if page_hint is not None else 'unknown'}\")\n",
    "                    segment_for_matching = segment\n",
    "                \n",
    "                matched_block, exact_match = find_matching_block(segment_for_matching, page_hint)\n",
    "                \n",
    "                # Always save the segment, even if no match is found\n",
    "                if matched_block:\n",
    "                    page_num = matched_block.get(\"page_num\", 0)\n",
    "                    page_annotation = f\"[Page {page_num+1}]\"\n",
    "                    \n",
    "                    # Store original segment in cache\n",
    "                    segment_data = {\n",
    "                        \"page\": page_num,\n",
    "                        \"text\": segment,\n",
    "                    }\n",
    "                    cached_data[\"segments\"].append(segment_data)\n",
    "                    \n",
    "                    # For display, ensure we have the correct page number\n",
    "                    if text_page is None:\n",
    "                        # No existing page annotation, add one\n",
    "                        display_text = f\"{page_annotation} {segment_for_matching}\"\n",
    "                    elif text_page != page_num:\n",
    "                        # Replace incorrect page annotation\n",
    "                        clean_segment = re.sub(r'\\[Page \\d+\\]\\s*', '', segment).strip()\n",
    "                        display_text = f\"{page_annotation} {clean_segment}\"\n",
    "                    else:\n",
    "                        display_text = segment  # Keep original if it had the correct page\n",
    "                    \n",
    "                    interesting_sections.append({\n",
    "                        \"page\": page_num,\n",
    "                        \"text\": display_text,\n",
    "                        \"category\": \"main\",\n",
    "                        \"bbox\": matched_block.get(\"occupy_space\"),\n",
    "                        \"page_text\": f\"Page {page_num+1}\"\n",
    "                    })\n",
    "                else:\n",
    "                    # Still save the segment with the hinted page or default to page 0\n",
    "                    default_page = page_hint if page_hint is not None else 0\n",
    "                    \n",
    "                    # Store the original segment in cache\n",
    "                    segment_data = {\n",
    "                        \"page\": default_page,\n",
    "                        \"text\": segment,\n",
    "                    }\n",
    "                    cached_data[\"segments\"].append(segment_data)\n",
    "                    \n",
    "                    # For display, use the page annotation from the text or add a default one\n",
    "                    if text_page is None:\n",
    "                        page_annotation = f\"[Page {default_page+1}]\"\n",
    "                        display_text = f\"{page_annotation} {segment}\"\n",
    "                    else:\n",
    "                        display_text = segment  # Keep original with its annotation\n",
    "                    \n",
    "                    print(f\"Using default page {default_page+1} for unmatched segment: {segment[:50]}...\")\n",
    "                    interesting_sections.append({\n",
    "                        \"page\": default_page,\n",
    "                        \"text\": display_text,\n",
    "                        \"category\": \"main\",\n",
    "                        \"bbox\": None,\n",
    "                        \"page_text\": f\"Page {default_page+1}\"\n",
    "                    })\n",
    "            \n",
    "            # Save results in structured format\n",
    "            with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(cached_data, f, indent=2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during interesting point extraction: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    print(f\"Found {len(interesting_sections)} interesting sections\")\n",
    "    return interesting_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_interesting_points(pdf_path, interesting_points, output_path):\n",
    "    \"\"\"Add highlights to the interesting points in the PDF with complete text block highlighting.\"\"\"\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    \n",
    "    # Using cyan highlight color for main content\n",
    "    highlight_color = (0, 1, 1)  # RGB for cyan\n",
    "    fail_count = 0\n",
    "    success_count = 0\n",
    "    \n",
    "    for point in interesting_points:\n",
    "        page_num = point[\"page\"]\n",
    "        page = doc[page_num]\n",
    "        text = point[\"text\"]\n",
    "        if not text:\n",
    "            print(f\"Empty text for page {page_num}\")\n",
    "            continue\n",
    "            \n",
    "        # Extract content without page annotations for better matching\n",
    "        clean_text = re.sub(r'\\[Page \\d+\\]\\s*', '', text).strip()\n",
    "        if not clean_text:\n",
    "            continue\n",
    "            \n",
    "        # Try exact match first\n",
    "        text_instances = page.search_for(clean_text)\n",
    "        \n",
    "        found_matches = []\n",
    "        if not text_instances:\n",
    "            # Method 1: Try normalized text (remove extra whitespace)\n",
    "            normalized_text = ' '.join(clean_text.split())\n",
    "            text_instances = page.search_for(normalized_text)\n",
    "            \n",
    "            # Method 2: Try with key phrases and collect all matches to combine later\n",
    "            if len(normalized_text.split()) > 10:\n",
    "                # Extract significant phrases (5-8 words)\n",
    "                words = normalized_text.split()\n",
    "                for i in range(len(words) - 5):\n",
    "                    phrase = ' '.join(words[i:i+min(8, len(words)-i)])\n",
    "                    if len(phrase) > 15:  # Only phrases with enough content\n",
    "                        phrase_instances = page.search_for(phrase)\n",
    "                        if phrase_instances:\n",
    "                            found_matches.extend(phrase_instances)\n",
    "            \n",
    "            # Method 3: Use key sentences and collect all matches\n",
    "            if '.' in normalized_text:\n",
    "                sentences = [s.strip() for s in normalized_text.split('.') if len(s.strip()) > 15]\n",
    "                for sentence in sentences:\n",
    "                    sentence_instances = page.search_for(sentence)\n",
    "                    if sentence_instances:\n",
    "                        found_matches.extend(sentence_instances)\n",
    "        \n",
    "        # If we found partial matches, combine their bounding boxes to highlight full area\n",
    "        if found_matches and not text_instances:\n",
    "            if len(found_matches) >= 2:\n",
    "                # Sort rectangles by y-coordinate and then by x-coordinate\n",
    "                found_matches.sort(key=lambda r: (r[1], r[0]))  # Sort by top-y then left-x\n",
    "                \n",
    "                # Combine all matches into one larger rectangle\n",
    "                x0 = min(rect[0] for rect in found_matches)\n",
    "                y0 = min(rect[1] for rect in found_matches)\n",
    "                x1 = max(rect[2] for rect in found_matches)\n",
    "                y1 = max(rect[3] for rect in found_matches)\n",
    "                \n",
    "                # Create a single combined rectangle that covers all matches\n",
    "                combined_rect = (x0, y0, x1, y1)\n",
    "                text_instances = [combined_rect]\n",
    "            else:\n",
    "                text_instances = found_matches\n",
    "        \n",
    "        # Highlight found instances or use bbox as fallback\n",
    "        if text_instances:\n",
    "            for inst in text_instances:\n",
    "                highlight = page.add_highlight_annot(inst)\n",
    "                highlight.set_colors(stroke=highlight_color)\n",
    "                highlight.update()\n",
    "            success_count += 1\n",
    "        elif point.get(\"bbox_list\") and isinstance(point[\"bbox_list\"], list) and point[\"bbox_list\"]:\n",
    "            # If we have a list of bounding boxes, highlight all of them\n",
    "            for bbox in point[\"bbox_list\"]:\n",
    "                if bbox:  # Make sure bbox is not None\n",
    "                    r = page.add_highlight_annot(bbox)\n",
    "                    r.set_colors(stroke=highlight_color)\n",
    "                    r.update()\n",
    "            success_count += 1\n",
    "        elif point.get(\"bbox\"):\n",
    "            # Single bbox case\n",
    "            r = page.add_highlight_annot(point[\"bbox\"])\n",
    "            r.set_colors(stroke=highlight_color)    \n",
    "            r.update()\n",
    "            success_count += 1\n",
    "        else:\n",
    "            # Last resort: try to find a text chunk on the page containing some keywords\n",
    "            if len(clean_text.split()) > 3:\n",
    "                key_words = [w for w in clean_text.split() if len(w) > 5][:5]\n",
    "                for word in key_words:\n",
    "                    word_instances = page.search_for(word)\n",
    "                    if word_instances:\n",
    "                        for inst in word_instances:\n",
    "                            highlight = page.add_highlight_annot(inst)\n",
    "                            highlight.set_colors(stroke=(1, 0.5, 0))  # Orange for partial matches\n",
    "                            highlight.update()\n",
    "                        success_count += 1\n",
    "                        break\n",
    "            else:\n",
    "                fail_count += 1\n",
    "    \n",
    "    print(f\"Successfully highlighted {success_count} segments\")\n",
    "    print(f\"Failed to highlight {fail_count} segments\")\n",
    "    \n",
    "    # Save the highlighted PDF\n",
    "    doc.save(output_path)\n",
    "    doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1763 text blocks\n",
      "Generating new interesting points with LLM...\n",
      "LLM response received\n",
      "Extracted 5 segments from LLM response\n",
      "Using segment marker page: Page unknown\n",
      "Finding matching block for: - <Page 22>\n",
      " It would seem that hystero-epilepsy e ...\n",
      "Page hint: None\n",
      "Using default page 1 for unmatched segment: - <Page 22>\n",
      " It would seem that hystero-epilepsy e...\n",
      "Using segment marker page: Page unknown\n",
      "Finding matching block for: - <Page 23>\n",
      " All this forms a whole whose parts fo ...\n",
      "Page hint: None\n",
      "Using default page 1 for unmatched segment: - <Page 23>\n",
      " All this forms a whole whose parts fo...\n",
      "Using segment marker page: Page unknown\n",
      "Finding matching block for: - <Page 41>\n",
      " Determining the facies appropriate to ...\n",
      "Page hint: None\n",
      "Using default page 1 for unmatched segment: - <Page 41>\n",
      " Determining the facies appropriate to...\n",
      "Using segment marker page: Page unknown\n",
      "Finding matching block for: - <Page 52>\n",
      " They were searching for the facies in ...\n",
      "Page hint: None\n",
      "Using default page 1 for unmatched segment: - <Page 52>\n",
      " They were searching for the facies in...\n",
      "Using segment marker page: Page unknown\n",
      "Finding matching block for: - <Page 38>\n",
      " My question is not only what purpose  ...\n",
      "Page hint: None\n",
      "Using default page 1 for unmatched segment: - <Page 38>\n",
      " My question is not only what purpose ...\n",
      "Found 5 interesting sections\n",
      "Identified 5 interesting points in main content\n",
      "Successfully highlighted 0 segments\n",
      "Failed to highlight 0 segments\n",
      "Created highlighted PDF: D:\\DATA300\\AudioBookSum\\pdf\\Didi Huberman_highlighted.pdf\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "base_name = os.path.splitext(input_pdf_path)[0]\n",
    "output = f\"{base_name}_highlighted.pdf\"\n",
    "chunked_data = chunk_text(content)\n",
    "# Initialize LLM\n",
    "try:\n",
    "    llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash', temperature=0.7)\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Gemini LLM: {e}\")\n",
    "    print(\"Make sure you have set GOOGLE_API_KEY in your environment or .env file\")\n",
    "    exit(1)\n",
    "words, extract_method = extract_text(input_pdf_path)\n",
    "# print(extract_method)\n",
    "\n",
    "print(f\"Extracted {len(words)} text blocks\")\n",
    "\n",
    "# Classify text blocks\n",
    "# classified_blocks = classify_text_blocks(words, extract_method)\n",
    "# print(\"Classified text blocks\")\n",
    "# # Identify interesting points (main content only)\n",
    "interesting_points = identify_interesting_points(chunked_data, llm, words, f\"{base_name}_interesting_points.txt\")  # Save to file\n",
    "# load from memory\n",
    "print(f\"Identified {len(interesting_points)} interesting points in main content\")\n",
    "\n",
    "# # Highlight interesting points in the PDF\n",
    "highlight_interesting_points(input_pdf_path, interesting_points, output)\n",
    "print(f\"Created highlighted PDF: {output}\")\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
