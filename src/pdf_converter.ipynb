{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pymupdf  \n",
    "import numpy as np\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "from pathlib import Path\n",
    "\n",
    "from mistralai.models import OCRResponse\n",
    "from IPython.display import Markdown, display\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "### Preprocessing\n",
    "- Extracting the text from the document via direct parsing or converting it into md using Mistral OCR then process\n",
    "- The reason behind this failsafe this because sometimes the document is scanned in and PyMuPDF doesn't recognize texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def replace_images_in_markdown(markdown_str: str, images_dict: dict) -> str:\n",
    "    \"\"\"\n",
    "    Replace image placeholders in markdown with base64-encoded images.\n",
    "\n",
    "    Args:\n",
    "        markdown_str: Markdown text containing image placeholders\n",
    "        images_dict: Dictionary mapping image IDs to base64 strings\n",
    "\n",
    "    Returns:\n",
    "        Markdown text with images replaced by base64 data\n",
    "    \"\"\"\n",
    "    for img_name, base64_str in images_dict.items():\n",
    "        markdown_str = markdown_str.replace(\n",
    "            f\"![{img_name}]({img_name})\", f\"![{img_name}]({base64_str})\"\n",
    "        )\n",
    "    return markdown_str\n",
    "\n",
    "def get_combined_markdown(ocr_response: OCRResponse) -> str:\n",
    "    \"\"\"\n",
    "    Combine OCR text and images into a single markdown document.\n",
    "\n",
    "    Args:\n",
    "        ocr_response: Response from OCR processing containing text and images\n",
    "\n",
    "    Returns:\n",
    "        Combined markdown string with embedded images\n",
    "    \"\"\"\n",
    "    markdowns: list[str] = []\n",
    "    # Extract images from page\n",
    "    for page in ocr_response.pages:\n",
    "        image_data = {}\n",
    "        for img in page.images:\n",
    "            image_data[img.id] = img.image_base64\n",
    "        # Replace image placeholders with actual images\n",
    "        markdowns.append(replace_images_in_markdown(page.markdown, image_data))\n",
    "\n",
    "    return \"\\n\\n\".join(markdowns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_Mistral_OCR(pdf_path):\n",
    "    api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "    if not api_key:\n",
    "        raise ValueError(\"MISTRAL_API_KEY not found in environment variables\")\n",
    "    \n",
    "    client = Mistral(api_key=api_key)\n",
    "    uploaded_file = client.files.upload(\n",
    "    file={\n",
    "            \"file_name\": pdf_path,\n",
    "            \"content\": open(pdf_path, \"rb\"),\n",
    "        },\n",
    "        purpose=\"ocr\",\n",
    "    )\n",
    "    print(client.files.retrieve(file_id=uploaded_file.id))\n",
    "    # Process the PDF with Mistral OCR\n",
    "    signed_url = client.files.get_signed_url(file_id=uploaded_file.id, expiry=1)\n",
    "\n",
    "    pdf_response = client.ocr.process(document={\"type\": \"document_url\",\"document_url\": signed_url.url,}, model=\"mistral-ocr-latest\", include_image_base64=True)\n",
    "    \n",
    "    # Display combined markdowns and images\n",
    "    # display(Markdown(get_combined_markdown(blocks)))\n",
    "    # We process it and save the combined markdown to a file\n",
    "    with open(\"combined_markdown.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(get_combined_markdown(pdf_response))\n",
    "    #SAVE THE RESPONSE TO A JSON FILE\n",
    "    all_pages = []\n",
    "    page_dimensions = []\n",
    "    ## TODO: This will need more work TO better process\n",
    "    for page_num, i in enumerate(pdf_response.pages):\n",
    "        all_pages.append({\"page\": page_num, \"text\":i.markdown, \"page_dimensions\": i.dimensions, \"images\": i.images})\n",
    "    return (all_pages, 'Mistral OCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_text_with_Mistral_OCR(r'D:\\DATA300\\AudioBookSum\\pdf\\Schoonover.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "def cluster_blocks_dbscan(blocks, eps=20, min_samples=2):\n",
    "    \"\"\"Cluster blocks using DBSCAN algorithm.\"\"\"\n",
    "    # Extract centroids of all blocks\n",
    "    centroids = np.array([[\n",
    "        (block['bbox'][0] + block['bbox'][2])/2,  # x center\n",
    "        (block['bbox'][1] + block['bbox'][3])/2   # y center\n",
    "    ] for block in blocks])\n",
    "    \n",
    "    # Run DBSCAN\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(centroids)\n",
    "    \n",
    "    # Group blocks by cluster\n",
    "    clusters = {}\n",
    "    for i, label in enumerate(clustering.labels_):\n",
    "        if label not in clusters:\n",
    "            clusters[label] = []\n",
    "        clusters[label].append(blocks[i])\n",
    "    \n",
    "    return list(clusters.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_blocks(blocks, eps=20, min_samples=1):\n",
    "    \"\"\"\n",
    "    Cluster text blocks, sort blocks within each cluster, and merge them.\n",
    "    \n",
    "    Args:\n",
    "        blocks: List of text block dictionaries with bbox and text\n",
    "        eps: DBSCAN epsilon parameter (clustering distance threshold)\n",
    "        min_samples: DBSCAN min_samples parameter\n",
    "        \n",
    "    Returns:\n",
    "        List of merged text blocks\n",
    "    \"\"\"\n",
    "    # Skip processing if no blocks\n",
    "    if not blocks:\n",
    "        return []\n",
    "    \n",
    "    # 1. Cluster blocks using DBSCAN\n",
    "    clusters = cluster_blocks_dbscan(blocks, eps, min_samples)\n",
    "    \n",
    "    # 2. Process each cluster\n",
    "    merged_blocks = []\n",
    "    for cluster in clusters:\n",
    "        # Sort blocks in reading order (top-to-bottom)\n",
    "        sorted_blocks = sorted(cluster, key=lambda b: (b['bbox'][2], b['bbox'][0]), reverse=False)\n",
    "        \n",
    "        if not sorted_blocks:\n",
    "            continue\n",
    "            \n",
    "        # 3. Merge blocks in the cluster\n",
    "        merged_text = \"\"\n",
    "        first_block = sorted_blocks[0]\n",
    "        x0, y0 = first_block['bbox'][0], first_block['bbox'][1]\n",
    "        x1, y1 = first_block['bbox'][2], first_block['bbox'][3]\n",
    "        block_no = first_block['block_no']\n",
    "        block_type = first_block['block_type']\n",
    "        page = first_block['page']\n",
    "        \n",
    "        prev_y1 = y0  # Track previous block's bottom coordinate\n",
    "        \n",
    "        for block in sorted_blocks:\n",
    "            # Update bounding box to encompass all blocks\n",
    "            x0 = min(x0, block['bbox'][0])\n",
    "            y0 = min(y0, block['bbox'][1])\n",
    "            x1 = max(x1, block['bbox'][2])\n",
    "            y1 = max(y1, block['bbox'][3])\n",
    "            \n",
    "            # Add line break if there's significant vertical gap\n",
    "            if merged_text and (block['bbox'][1] - prev_y1) > 0.5 * (block['text_height']):\n",
    "                merged_text += \"\\n\"\n",
    "                \n",
    "            # Add space only if needed (avoid double spaces)\n",
    "            if merged_text and not merged_text.endswith(\"\\n\"):\n",
    "                merged_text += \" \"\n",
    "                \n",
    "            merged_text += block['text']\n",
    "            prev_y1 = block['bbox'][3]\n",
    "        \n",
    "        # 4. Create a new merged block\n",
    "        merged_block = {\n",
    "            \"page\": page,\n",
    "            \"bbox\": (x0, y0, x1, y1),\n",
    "            \"text\": merged_text,\n",
    "            \"block_no\": block_no,\n",
    "            \"block_type\": block_type,\n",
    "            \"text_height\": block['text_height'],\n",
    "            \"is_merged_cluster\": True\n",
    "        }\n",
    "        \n",
    "        merged_blocks.append(merged_block)\n",
    "    \n",
    "    return merged_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(pdf_path:str)-> tuple[List[dict], str]:\n",
    "    \"\"\"PyMuPDF-based function to extract text with bounding boxes from a PDF file.\"\"\"\n",
    "    try:\n",
    "        doc = pymupdf.open(pdf_path, filetype=\"pdf\")\n",
    "        prev_block = None\n",
    "        all_blocks = []\n",
    "        for page_num, page in enumerate(doc):\n",
    "            words = page.get_text(\"words\")\n",
    "            page_block = []\n",
    "            # Take threshold based on page_width and page_height\n",
    "            WIDTH_threshold = (0.02 if page.rect.width > page.rect.height else 0.0092625) * page.rect.width\n",
    "            HEIGHT_threshold = (0.01 if page.rect.width > page.rect.height else 0.05) * page.rect.height\n",
    "            for curr_word in words:\n",
    "                # Each block is (x0, y0, x1, y1, text, block_no, block_type)\n",
    "                x0, y0, x1, y1, text, block_no, line_no, block_type = curr_word\n",
    "                text_height = y1 - y0\n",
    "                if not text.strip():\n",
    "                    continue\n",
    "                is_mergable = False\n",
    "                \n",
    "                \"\"\"\n",
    "                Check if the current block is close to the previous block.\n",
    "                The conditions are:\n",
    "                (1. The x-coordinates of the current block are within WIDTH_threshold of the previous block.\n",
    "                2. The y-coordinates of the current block are within HEIGHT_threshold of the previous block.\n",
    "                (3. The current block is not completely to the left of the previous block.\n",
    "                4. The y-coordinates of the current block are within 4 pixels of the previous block.\n",
    "                5. The current block is not completely to the right of the previous block.\n",
    "                \"\"\"\n",
    "                if prev_block and abs(text_height - prev_block[-1]) <= 0 and \\\n",
    "                    (\\\n",
    "                        (abs(x0 - prev_block[2]) <= WIDTH_threshold and (y0 -prev_block[3]) <= HEIGHT_threshold) \\\n",
    "                        # or ((not (prev_block[2] < x0 and x1 < prev_block[0])) and (y0 -prev_block[3]) <= 8)\\\n",
    "                    ):\n",
    "                    prev_block[2] = max(prev_block[2], x1) \n",
    "                    prev_block[3] = max(prev_block[3], y1) \n",
    "                    prev_block[4] += \" \" + text.strip()\n",
    "                    is_mergable = True\n",
    "\n",
    "                if is_mergable and page_block:\n",
    "                    page_block.pop()\n",
    "                    page_block.append(\n",
    "                        {\n",
    "                            \"page\": page_num,\n",
    "                            \"bbox\": (prev_block[0], prev_block[1], prev_block[2], prev_block[3]),\n",
    "                            \"text\": prev_block[4],\n",
    "                            \"block_no\": block_no,\n",
    "                            \"block_type\": block_type,\n",
    "                            \"text_height\": prev_block[-1]\n",
    "                        }\n",
    "                    )    \n",
    "                    prev_block = [prev_block[0], prev_block[1], prev_block[2], prev_block[3], prev_block[4], block_no, block_type, prev_block[-1]]\n",
    "                else:\n",
    "                    page_block.append({\n",
    "                        \"page\": page_num,\n",
    "                        \"bbox\": (x0, y0, x1, y1),\n",
    "                        \"text\": text.strip(),\n",
    "                        \"block_no\": block_no,\n",
    "                        \"block_type\": block_type,\n",
    "                        \"text_height\": text_height\n",
    "                    })\n",
    "                    # Update the previous block\n",
    "                    prev_block = [x0, y0, x1, y1, text.strip(), block_no, block_type, text_height]\n",
    "            merged_blocks = process_text_blocks(page_block, eps=25, min_samples=1)\n",
    "            all_blocks.extend(merged_blocks)\n",
    "        doc.close()\n",
    "        # Remove empty blocks\n",
    "        if not all_blocks:\n",
    "            raise Exception(\"PyMuPDF Failed or No text found in the PDF.\")\n",
    "        return (all_blocks, 'pyMuPDF')\n",
    "    except Exception as e:\n",
    "        print(\"The Error is\", e.with_traceback())\n",
    "        # return extract_text_with_Mistral_OCR(pdf_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_path = r'D:\\DATA300\\AudioBookSum\\pdf\\Gilman.pdf'\n",
    "# words, extraction_method = extract_text(pdf_path)\n",
    "# # Dataframe box\n",
    "# df = pd.DataFrame(words)\n",
    "# df[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: D:\\DATA300\\AudioBookSum\\pdf\\Clopath.pdf\n",
      "pyMuPDF\n",
      "Extracted 42 text blocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meapb\\AppData\\Local\\Temp\\ipykernel_12556\\806658423.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  middle_df.sort_values(by='text_count', ascending=False, inplace=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "page",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "space",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "text_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_height",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ratio",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0614a59f-eb8e-485e-b7a5-c0cc4eabfb1d",
       "rows": [
        [
         "11",
         "33' VERSUS\nseen through the mind of the artist and no artist sees exactly what\nit is not. We know that it is not imitation, neither mere technique,\nof horses taken while they are running at full speed do not give the not express such strength and power if they were mere copies from of art, or, as Taine says, \" Photographv would be superior to painting, The source of art is the perception of the beautiful, the emotion word art has also often beeni applied specially to the art of drawing and painting in all their different phases, so that to say a person is\nnature. A sketch has often more value than a finished picture, because There are artists in all trades, as well as in all professions where\nWe may -learn something more about what art is by recalling what ful, a-language. Art can express itself by means of sounds in music,\nthe outcome of his desire to express that emotion. Art is nature which the artist feels in the presence of nature, and works of art are\nEven in photography perfect exactness, as it is obtained by instan Art is sometimes purposely inexact. Michel Angelo's figures would by means of words in poetry, or in painting by means of forms and\nThere is some imitation in art, but perfect exactness is not art.\ntaneous process, sometimes spoils the general effect. Photographs mon to all true artists, and all real works of art are the expression of We find that art means skill, but in the fine arts this is but one of\nand the court reports, where every word and gesture are carefully nor mere talent, nor inspiration. Imitation is not the supreme aim mind or imagination is chiefly concerned. Poetry, music, painting,\nthis. Different definitions or interpretations of art are given by differ ent writers. It has been called imagination, the sense of the beauti the elements. There is an emotion, a poetical feeling, which is com engaged in art work often means only somie kind of work in the sculpture, and architecture are commonly called the fine arts. The as in manual labor. As there is always a best way for doing any thing; skill in the attainment of a desired end; skill in mental as well\nthing, the perfection of it is an art; and the one who does it best, an means in general, skill-skill in making, arranging, or fitting some lf we study the word \"art\" and its etymology we find that it",
         "1",
         "119635.42421955476",
         "410",
         "11.145721435546875",
         "0.0034270785820725526"
        ],
        [
         "30",
         "more to do. We need not fear VERSUS\nanything in time entirely supersede the art of painting. Some people seem to\nphotography may rid us in time of all the poor work done in color.\nhis own perception of the beautiful, his own creation in fact, can no The cheapness of such pictures ought to warn us against them.\nIs not the hand-work upon them done mostly by men and women who Are they not often advertised as given away for the sale of the frame?\nThe work of the artist, however, in which is seen his own individuality, never had any art training at all? If we cannot afford portraits painted by artists of some taste and education, why not be satisfied with photo\nThe fear has sometimes been expressed that photography would\nthink that when the process of taking photographs in colors has been perfected and made common enough, the painter will have nothing",
         "3",
         "50478.39595078264",
         "149",
         "10.930160522460938",
         "0.0029517578202222935"
        ],
        [
         "26",
         "a at be\ncan\nnot and a\nlack\nwith soon We\nwork to\nment The The\nbe effect\nalso\nof see\nor\nfriend. painting\nanything one given of\ncome more be best\nIt\nso photographer\npicture By Charles H. Davis\nand\nor whatever finishing.\nmisunderstood\nendured taste. is\nto-day very speed\nwhen second\na He\nless\nexcellent would works\nmay and at\nwatching\nupon are\nmerit\nbe in more\nbe\ninartistic can\nskill\na all.\nhelpful or\nlike in them.\ntheir to really\nportraits,\na The\neither misused.\nmakes less attain\ndeplorable photography,\nmachinery, a the\nwonder an\nart\nblack walls\nthe very\nif which form\nbut by\nfriend, photography\nit artist\nare\nor beautiful\nought tendency and\nprocess\neffect painter,\ncrayon\nthat are in\nto to\nwere\nall people or different\nbut his not\nvery results\nthe rather, not, who posse wa\nli som enlarged pe\ni tha\ncomb\nl position\nresultin\nm from",
         "2",
         "65654.2421619976",
         "85",
         "10.15667724609375",
         "0.0012946612008751545"
        ],
        [
         "4",
         "Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. range of content in a trusted digital archive. We use information technology and tools to increase productivity and JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide",
         "0",
         "24539.140478395857",
         "67",
         "11.412002563476562",
         "0.002730331979597512"
        ],
        [
         "8",
         "This content downloaded from All use subject to https://about.jstor.org/terms 73.121.89.56 on Thu, 01 Apr 2021 00:58:41 UTC",
         "0",
         "4261.545029953122",
         "17",
         "10.6719970703125",
         "0.003989163526493818"
        ],
        [
         "41",
         "This content downloaded from All use subject to https://about.jstor.org/terms 73.121.89.56 on Thu, 01 Apr 2021 00:58:41 UTC",
         "3",
         "4261.545029953122",
         "17",
         "10.6719970703125",
         "0.003989163526493818"
        ],
        [
         "27",
         "This content downloaded from All use subject to https://about.jstor.org/terms 73.121.89.56 on Thu, 01 Apr 2021 00:58:41 UTC",
         "2",
         "4261.544826461934",
         "17",
         "10.6719970703125",
         "0.003989163716978644"
        ],
        [
         "19",
         "This content downloaded from All use subject to https://about.jstor.org/terms 73.121.89.56 on Thu, 01 Apr 2021 00:58:41 UTC",
         "1",
         "4261.545436935499",
         "17",
         "10.6719970703125",
         "0.003989163145524219"
        ],
        [
         "1",
         "Source: Brush and Pencil , Mar., 1901, Vol. 7, No. 6 (Mar., 1901), pp. 331-333",
         "0",
         "6788.341994195245",
         "15",
         "15.215995788574219",
         "0.0022096706401690718"
        ],
        [
         "7",
         "are collaborating with JSTOR to digitize, preserve and extend access to Brush and Pencil",
         "0",
         "4504.359763337299",
         "14",
         "11.4119873046875",
         "0.003108099871140697"
        ],
        [
         "18",
         "it shows only the principal characteristics of the subject.",
         "1",
         "2085.8606386631727",
         "9",
         "10.15667724609375",
         "0.004314765729396043"
        ],
        [
         "33",
         "graphs, which can be very artistic in their way?",
         "3",
         "2313.860188703751",
         "9",
         "10.397598266601562",
         "0.0038896040668048725"
        ],
        [
         "37",
         "more perish than the soul which inspired it.",
         "3",
         "2113.2528281165287",
         "8",
         "10.397598266601562",
         "0.0037856331687156105"
        ],
        [
         "0",
         "Author(s): Henrietta Clopath Genuine Art versus Mechanism",
         "0",
         "6476.222485284321",
         "7",
         "15.215995788574219",
         "0.00108087701061936"
        ],
        [
         "39",
         "END OF A NOVEMBER DAY-PHOTOGRAPH",
         "3",
         "1384.392321931664",
         "5",
         "8.673126220703125",
         "0.0036116929578339637"
        ],
        [
         "17",
         "noticed, the greatest literary works.\"",
         "1",
         "1432.2207711715018",
         "5",
         "10.397613525390625",
         "0.0034910818922910826"
        ],
        [
         "2",
         "Published by: ;",
         "0",
         "1314.4191640322097",
         "3",
         "15.21600341796875",
         "0.002282376948002628"
        ],
        [
         "3",
         "Stable URL: https://www.jstor.org/stable/25505621",
         "0",
         "4617.966488016769",
         "3",
         "15.21600341796875",
         "0.000649636589564854"
        ],
        [
         "16",
         "another has seen.",
         "1",
         "746.0350530148717",
         "3",
         "11.145721435546875",
         "0.004021258770451094"
        ],
        [
         "38",
         "HENRlETTA CLOPATH.",
         "3",
         "1065.614364793757",
         "2",
         "10.397598266601562",
         "0.0018768515760268375"
        ],
        [
         "14",
         "\"graphic arts.\"",
         "1",
         "760.0009559802711",
         "2",
         "12.134750366210938",
         "0.002631575637191591"
        ],
        [
         "22",
         "AND",
         "2",
         "377.65360500710085",
         "1",
         "11.386638641357422",
         "0.00264792917833049"
        ],
        [
         "21",
         "BRUSH",
         "2",
         "579.7952827798435",
         "1",
         "11.386638641357422",
         "0.0017247466988787388"
        ],
        [
         "15",
         "colors.",
         "1",
         "328.8285680785775",
         "1",
         "12.134765625",
         "0.0030410983019000895"
        ],
        [
         "5",
         "https://about.jstor.org/terms",
         "0",
         "1515.4570336542092",
         "1",
         "11.412002563476562",
         "0.0006598669429701403"
        ],
        [
         "9",
         "GENUINE",
         "1",
         "806.4110071223695",
         "1",
         "14.987754821777344",
         "0.0012400624385925008"
        ],
        [
         "10",
         "ART",
         "1",
         "373.6203762644436",
         "1",
         "14.987754821777344",
         "0.0026765135509959795"
        ],
        [
         "12",
         "MECHANISM",
         "1",
         "1096.4134057372576",
         "1",
         "14.987754821777344",
         "0.0009120647328528178"
        ],
        [
         "13",
         "artist.",
         "1",
         "281.6020875083632",
         "1",
         "11.386642456054688",
         "0.003551110039162268"
        ],
        [
         "29",
         "ART",
         "3",
         "316.7536308025592",
         "1",
         "12.996997833251953",
         "0.0031570277425590934"
        ],
        [
         "28",
         "GENUINE",
         "3",
         "683.6712190091203",
         "1",
         "12.996997833251953",
         "0.001462691381757084"
        ],
        [
         "24",
         "FLYING",
         "2",
         "330.16154333297163",
         "1",
         "8.1785888671875",
         "0.0030288203462614928"
        ],
        [
         "25",
         "CLOUD)S-PAINTING",
         "2",
         "850.6053145956248",
         "1",
         "8.1785888671875",
         "0.001175633378772618"
        ],
        [
         "23",
         "PENCIL",
         "2",
         "609.1914221800398",
         "1",
         "11.386638641357422",
         "0.0016415201586742977"
        ],
        [
         "35",
         "Perfection",
         "3",
         "565.6263149902225",
         "1",
         "11.145721435546875",
         "0.0017679516908920446"
        ],
        [
         "31",
         "MECHANISM",
         "3",
         "929.5346313671325",
         "1",
         "12.996997833251953",
         "0.0010758071472057248"
        ],
        [
         "32",
         "333",
         "3",
         "241.95881958701648",
         "1",
         "12.996997833251953",
         "0.0041329346940393984"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 37
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>page</th>\n",
       "      <th>space</th>\n",
       "      <th>text_count</th>\n",
       "      <th>text_height</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33' VERSUS\\nseen through the mind of the artis...</td>\n",
       "      <td>1</td>\n",
       "      <td>119635.424220</td>\n",
       "      <td>410</td>\n",
       "      <td>11.145721</td>\n",
       "      <td>0.003427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>more to do. We need not fear VERSUS\\nanything ...</td>\n",
       "      <td>3</td>\n",
       "      <td>50478.395951</td>\n",
       "      <td>149</td>\n",
       "      <td>10.930161</td>\n",
       "      <td>0.002952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>a at be\\ncan\\nnot and a\\nlack\\nwith soon We\\nw...</td>\n",
       "      <td>2</td>\n",
       "      <td>65654.242162</td>\n",
       "      <td>85</td>\n",
       "      <td>10.156677</td>\n",
       "      <td>0.001295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your use of the JSTOR archive indicates your a...</td>\n",
       "      <td>0</td>\n",
       "      <td>24539.140478</td>\n",
       "      <td>67</td>\n",
       "      <td>11.412003</td>\n",
       "      <td>0.002730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This content downloaded from All use subject t...</td>\n",
       "      <td>0</td>\n",
       "      <td>4261.545030</td>\n",
       "      <td>17</td>\n",
       "      <td>10.671997</td>\n",
       "      <td>0.003989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>This content downloaded from All use subject t...</td>\n",
       "      <td>3</td>\n",
       "      <td>4261.545030</td>\n",
       "      <td>17</td>\n",
       "      <td>10.671997</td>\n",
       "      <td>0.003989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>This content downloaded from All use subject t...</td>\n",
       "      <td>2</td>\n",
       "      <td>4261.544826</td>\n",
       "      <td>17</td>\n",
       "      <td>10.671997</td>\n",
       "      <td>0.003989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>This content downloaded from All use subject t...</td>\n",
       "      <td>1</td>\n",
       "      <td>4261.545437</td>\n",
       "      <td>17</td>\n",
       "      <td>10.671997</td>\n",
       "      <td>0.003989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Source: Brush and Pencil , Mar., 1901, Vol. 7,...</td>\n",
       "      <td>0</td>\n",
       "      <td>6788.341994</td>\n",
       "      <td>15</td>\n",
       "      <td>15.215996</td>\n",
       "      <td>0.002210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>are collaborating with JSTOR to digitize, pres...</td>\n",
       "      <td>0</td>\n",
       "      <td>4504.359763</td>\n",
       "      <td>14</td>\n",
       "      <td>11.411987</td>\n",
       "      <td>0.003108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>it shows only the principal characteristics of...</td>\n",
       "      <td>1</td>\n",
       "      <td>2085.860639</td>\n",
       "      <td>9</td>\n",
       "      <td>10.156677</td>\n",
       "      <td>0.004315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>graphs, which can be very artistic in their way?</td>\n",
       "      <td>3</td>\n",
       "      <td>2313.860189</td>\n",
       "      <td>9</td>\n",
       "      <td>10.397598</td>\n",
       "      <td>0.003890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>more perish than the soul which inspired it.</td>\n",
       "      <td>3</td>\n",
       "      <td>2113.252828</td>\n",
       "      <td>8</td>\n",
       "      <td>10.397598</td>\n",
       "      <td>0.003786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Author(s): Henrietta Clopath Genuine Art versu...</td>\n",
       "      <td>0</td>\n",
       "      <td>6476.222485</td>\n",
       "      <td>7</td>\n",
       "      <td>15.215996</td>\n",
       "      <td>0.001081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>END OF A NOVEMBER DAY-PHOTOGRAPH</td>\n",
       "      <td>3</td>\n",
       "      <td>1384.392322</td>\n",
       "      <td>5</td>\n",
       "      <td>8.673126</td>\n",
       "      <td>0.003612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>noticed, the greatest literary works.\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1432.220771</td>\n",
       "      <td>5</td>\n",
       "      <td>10.397614</td>\n",
       "      <td>0.003491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Published by: ;</td>\n",
       "      <td>0</td>\n",
       "      <td>1314.419164</td>\n",
       "      <td>3</td>\n",
       "      <td>15.216003</td>\n",
       "      <td>0.002282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stable URL: https://www.jstor.org/stable/25505621</td>\n",
       "      <td>0</td>\n",
       "      <td>4617.966488</td>\n",
       "      <td>3</td>\n",
       "      <td>15.216003</td>\n",
       "      <td>0.000650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>another has seen.</td>\n",
       "      <td>1</td>\n",
       "      <td>746.035053</td>\n",
       "      <td>3</td>\n",
       "      <td>11.145721</td>\n",
       "      <td>0.004021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>HENRlETTA CLOPATH.</td>\n",
       "      <td>3</td>\n",
       "      <td>1065.614365</td>\n",
       "      <td>2</td>\n",
       "      <td>10.397598</td>\n",
       "      <td>0.001877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"graphic arts.\"</td>\n",
       "      <td>1</td>\n",
       "      <td>760.000956</td>\n",
       "      <td>2</td>\n",
       "      <td>12.134750</td>\n",
       "      <td>0.002632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AND</td>\n",
       "      <td>2</td>\n",
       "      <td>377.653605</td>\n",
       "      <td>1</td>\n",
       "      <td>11.386639</td>\n",
       "      <td>0.002648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BRUSH</td>\n",
       "      <td>2</td>\n",
       "      <td>579.795283</td>\n",
       "      <td>1</td>\n",
       "      <td>11.386639</td>\n",
       "      <td>0.001725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>colors.</td>\n",
       "      <td>1</td>\n",
       "      <td>328.828568</td>\n",
       "      <td>1</td>\n",
       "      <td>12.134766</td>\n",
       "      <td>0.003041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://about.jstor.org/terms</td>\n",
       "      <td>0</td>\n",
       "      <td>1515.457034</td>\n",
       "      <td>1</td>\n",
       "      <td>11.412003</td>\n",
       "      <td>0.000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GENUINE</td>\n",
       "      <td>1</td>\n",
       "      <td>806.411007</td>\n",
       "      <td>1</td>\n",
       "      <td>14.987755</td>\n",
       "      <td>0.001240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ART</td>\n",
       "      <td>1</td>\n",
       "      <td>373.620376</td>\n",
       "      <td>1</td>\n",
       "      <td>14.987755</td>\n",
       "      <td>0.002677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MECHANISM</td>\n",
       "      <td>1</td>\n",
       "      <td>1096.413406</td>\n",
       "      <td>1</td>\n",
       "      <td>14.987755</td>\n",
       "      <td>0.000912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>artist.</td>\n",
       "      <td>1</td>\n",
       "      <td>281.602088</td>\n",
       "      <td>1</td>\n",
       "      <td>11.386642</td>\n",
       "      <td>0.003551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ART</td>\n",
       "      <td>3</td>\n",
       "      <td>316.753631</td>\n",
       "      <td>1</td>\n",
       "      <td>12.996998</td>\n",
       "      <td>0.003157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GENUINE</td>\n",
       "      <td>3</td>\n",
       "      <td>683.671219</td>\n",
       "      <td>1</td>\n",
       "      <td>12.996998</td>\n",
       "      <td>0.001463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FLYING</td>\n",
       "      <td>2</td>\n",
       "      <td>330.161543</td>\n",
       "      <td>1</td>\n",
       "      <td>8.178589</td>\n",
       "      <td>0.003029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CLOUD)S-PAINTING</td>\n",
       "      <td>2</td>\n",
       "      <td>850.605315</td>\n",
       "      <td>1</td>\n",
       "      <td>8.178589</td>\n",
       "      <td>0.001176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PENCIL</td>\n",
       "      <td>2</td>\n",
       "      <td>609.191422</td>\n",
       "      <td>1</td>\n",
       "      <td>11.386639</td>\n",
       "      <td>0.001642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Perfection</td>\n",
       "      <td>3</td>\n",
       "      <td>565.626315</td>\n",
       "      <td>1</td>\n",
       "      <td>11.145721</td>\n",
       "      <td>0.001768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MECHANISM</td>\n",
       "      <td>3</td>\n",
       "      <td>929.534631</td>\n",
       "      <td>1</td>\n",
       "      <td>12.996998</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>333</td>\n",
       "      <td>3</td>\n",
       "      <td>241.958820</td>\n",
       "      <td>1</td>\n",
       "      <td>12.996998</td>\n",
       "      <td>0.004133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  page          space  \\\n",
       "11  33' VERSUS\\nseen through the mind of the artis...     1  119635.424220   \n",
       "30  more to do. We need not fear VERSUS\\nanything ...     3   50478.395951   \n",
       "26  a at be\\ncan\\nnot and a\\nlack\\nwith soon We\\nw...     2   65654.242162   \n",
       "4   Your use of the JSTOR archive indicates your a...     0   24539.140478   \n",
       "8   This content downloaded from All use subject t...     0    4261.545030   \n",
       "41  This content downloaded from All use subject t...     3    4261.545030   \n",
       "27  This content downloaded from All use subject t...     2    4261.544826   \n",
       "19  This content downloaded from All use subject t...     1    4261.545437   \n",
       "1   Source: Brush and Pencil , Mar., 1901, Vol. 7,...     0    6788.341994   \n",
       "7   are collaborating with JSTOR to digitize, pres...     0    4504.359763   \n",
       "18  it shows only the principal characteristics of...     1    2085.860639   \n",
       "33   graphs, which can be very artistic in their way?     3    2313.860189   \n",
       "37       more perish than the soul which inspired it.     3    2113.252828   \n",
       "0   Author(s): Henrietta Clopath Genuine Art versu...     0    6476.222485   \n",
       "39                   END OF A NOVEMBER DAY-PHOTOGRAPH     3    1384.392322   \n",
       "17             noticed, the greatest literary works.\"     1    1432.220771   \n",
       "2                                     Published by: ;     0    1314.419164   \n",
       "3   Stable URL: https://www.jstor.org/stable/25505621     0    4617.966488   \n",
       "16                                  another has seen.     1     746.035053   \n",
       "38                                 HENRlETTA CLOPATH.     3    1065.614365   \n",
       "14                                    \"graphic arts.\"     1     760.000956   \n",
       "22                                                AND     2     377.653605   \n",
       "21                                              BRUSH     2     579.795283   \n",
       "15                                            colors.     1     328.828568   \n",
       "5                       https://about.jstor.org/terms     0    1515.457034   \n",
       "9                                             GENUINE     1     806.411007   \n",
       "10                                                ART     1     373.620376   \n",
       "12                                          MECHANISM     1    1096.413406   \n",
       "13                                            artist.     1     281.602088   \n",
       "29                                                ART     3     316.753631   \n",
       "28                                            GENUINE     3     683.671219   \n",
       "24                                             FLYING     2     330.161543   \n",
       "25                                   CLOUD)S-PAINTING     2     850.605315   \n",
       "23                                             PENCIL     2     609.191422   \n",
       "35                                         Perfection     3     565.626315   \n",
       "31                                          MECHANISM     3     929.534631   \n",
       "32                                                333     3     241.958820   \n",
       "\n",
       "    text_count  text_height     ratio  \n",
       "11         410    11.145721  0.003427  \n",
       "30         149    10.930161  0.002952  \n",
       "26          85    10.156677  0.001295  \n",
       "4           67    11.412003  0.002730  \n",
       "8           17    10.671997  0.003989  \n",
       "41          17    10.671997  0.003989  \n",
       "27          17    10.671997  0.003989  \n",
       "19          17    10.671997  0.003989  \n",
       "1           15    15.215996  0.002210  \n",
       "7           14    11.411987  0.003108  \n",
       "18           9    10.156677  0.004315  \n",
       "33           9    10.397598  0.003890  \n",
       "37           8    10.397598  0.003786  \n",
       "0            7    15.215996  0.001081  \n",
       "39           5     8.673126  0.003612  \n",
       "17           5    10.397614  0.003491  \n",
       "2            3    15.216003  0.002282  \n",
       "3            3    15.216003  0.000650  \n",
       "16           3    11.145721  0.004021  \n",
       "38           2    10.397598  0.001877  \n",
       "14           2    12.134750  0.002632  \n",
       "22           1    11.386639  0.002648  \n",
       "21           1    11.386639  0.001725  \n",
       "15           1    12.134766  0.003041  \n",
       "5            1    11.412003  0.000660  \n",
       "9            1    14.987755  0.001240  \n",
       "10           1    14.987755  0.002677  \n",
       "12           1    14.987755  0.000912  \n",
       "13           1    11.386642  0.003551  \n",
       "29           1    12.996998  0.003157  \n",
       "28           1    12.996998  0.001463  \n",
       "24           1     8.178589  0.003029  \n",
       "25           1     8.178589  0.001176  \n",
       "23           1    11.386639  0.001642  \n",
       "35           1    11.145721  0.001768  \n",
       "31           1    12.996998  0.001076  \n",
       "32           1    12.996998  0.004133  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_pdf_path = r'D:\\DATA300\\AudioBookSum\\pdf\\Clopath.pdf'\n",
    "pdf_file = Path(input_pdf_path)\n",
    "assert pdf_file.is_file()\n",
    "base_name = os.path.splitext(input_pdf_path)[0]\n",
    "output = f\"{base_name}_highlighted.pdf\"\n",
    "print(f\"Processing PDF: {input_pdf_path}\")\n",
    "\n",
    "# Extract text and bounding boxes\n",
    "words, extract_method = extract_text(input_pdf_path)\n",
    "print(extract_method)\n",
    "# Keep track of the median word height\n",
    "\n",
    "print(f\"Extracted {len(words)} text blocks\")\n",
    "data = []\n",
    "for curr_word in words:\n",
    "\n",
    "    text = curr_word[\"text\"].strip() if isinstance(curr_word.get(\"text\"), str) else \"\"\n",
    "    \n",
    "    # Improved footnote detection\n",
    "    footnote_markers = [\"*\", \"†\", \"‡\", \"§\", \"¶\", \"⁂\", \"⁎\", \"⁑\", \"⁕\"]\n",
    "    # Text density in space\n",
    "    # How to consistently identify the threshold\n",
    "    is_foot_note_marker = False\n",
    "    # Calculate the distance between the text and the space it occupies\n",
    "    # x0,y0,x1,y1\n",
    "    space = (curr_word[\"bbox\"][2] - curr_word[\"bbox\"][0]) * (curr_word[\"bbox\"][3] - curr_word[\"bbox\"][1])\n",
    "    text_count = len(text.split(\" \"))\n",
    "    data.append(\n",
    "        {\n",
    "            \"text\": text,\n",
    "            \"page\": curr_word[\"page\"],\n",
    "            \"space\": space,\n",
    "            \"text_count\": text_count,\n",
    "            \"text_height\": curr_word[\"text_height\"],\n",
    "            \"ratio\": text_count / space if space > 0 else 0,\n",
    "        }\n",
    "    )\n",
    "    is_footnote_marker = False\n",
    "    # Classification logic\n",
    "    if is_footnote_marker:\n",
    "        classification = \"footnote\"\n",
    "    else:\n",
    "        classification = \"main\"\n",
    "\n",
    "    curr_word[\"category\"] = classification\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "df['ratio'].median()\n",
    "lower_q = df['ratio'].quantile(0.0)\n",
    "upper_q = df['ratio'].quantile(0.9)\n",
    "\n",
    "middle_df = df[(df['ratio'] >= lower_q) & (df['ratio'] <= upper_q) & (df['text_count'] > 0)]\n",
    "middle_df.sort_values(by='text_count', ascending=False, inplace=True)\n",
    "middle_df\n",
    "#Plot out the frequency of text height\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(df[\"text_height\"], bins=30, color='blue', alpha=0.7)\n",
    "# plt.xlabel(\"Text Height\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.title(\"Histogram of Text Height\")\n",
    "# plt.grid(axis='y', alpha=0.75)\n",
    "# plt.show()\n",
    "# df\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(df[\"ratio\"], bins=30, color='blue', alpha=0.7)\n",
    "# plt.xlabel(\"Text Count to Space Ratio\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.title(\"Histogram of Text Count to Space Ratio\")\n",
    "# plt.grid(axis='y', alpha=0.75)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(blocks, chunk_size:int=1000, chunk_overlap:int=100):\n",
    "    \"\"\"Chunk text blocks into smaller pieces for processing.\n",
    "        Args:\n",
    "            chunk_size (int): Size of each chunk. Default is 1000 characters.\n",
    "            chunk_overlap (int): Number of overlapping characters between chunks. Default is 200.\n",
    "    \"\"\"\n",
    "    # Separate blocks by category\n",
    "    categories = {\"main\": [], \"footnote\": [], \"extra\": []}\n",
    "    for block in blocks:\n",
    "        categories[block[\"category\"]].append(block)\n",
    "    \n",
    "    chunked_data = {}\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "    )\n",
    "    \n",
    "    for category, category_blocks in categories.items():\n",
    "        # Extract text from blocks\n",
    "        texts = [block[\"text\"] for block in category_blocks]\n",
    "        full_text = \"\\n\\n\".join(texts)\n",
    "        \n",
    "        # Chunk the text\n",
    "        chunks = text_splitter.split_text(full_text)\n",
    "        chunked_data[category] = chunks\n",
    "    \n",
    "    return chunked_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_interesting_points(chunked_data, llm, blocks, file_name):\n",
    "    \"\"\"Use an LLM to identify interesting or important points in the text.\"\"\"\n",
    "    interesting_sections = []\n",
    "    \n",
    "    # Only process the 'main' category\n",
    "    if 'main' not in chunked_data:\n",
    "        print(\"No main content identified in the document\")\n",
    "        return interesting_sections\n",
    "        \n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"\"\"\n",
    "        You are a reasoning summarizer.\n",
    "        Summarize the provided text and support your summary using at least 20 verbatim snippets from the original text.\n",
    "        Remember:\n",
    "        The reasoning section must ONLY contain verbatim text from the document\n",
    "        Every sentence in the reasoning must be supporting sentences in the summary section\n",
    "        Do not add any information that isn't directly from the documentFormat:\n",
    "        ```segment 1```\n",
    "        ```segment 2```\n",
    "        Below is text from the main content of a document in English:\n",
    "        {text}\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # for chunk in chunked_data['main']:\n",
    "    chunk = \"\\n\".join(chunked_data['main'])\n",
    "    \n",
    "    prompt = prompt_template.format(text=chunk)\n",
    "    interesting_points = []\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f.readlines():\n",
    "                if not len(line.strip()):\n",
    "                    continue\n",
    "                interesting_points.append(line)\n",
    "            for segment in interesting_points:\n",
    "                threshold = threshold = len(segment.split(\" \"))\n",
    "                segment = segment.strip()\n",
    "                if len(segment.split()) < threshold:\n",
    "                    continue\n",
    "                for block in blocks:\n",
    "                    intersect_more_more_than_threshold = False\n",
    "                    if len(segment.split()) >= threshold:\n",
    "                        count = 0\n",
    "                        for chip in segment.split(\" \"):\n",
    "                            if chip in block[\"text\"]:\n",
    "                                count += 1\n",
    "                        # print(\"count:\", count, \"len:\", len(segment.split()), \"threshold:\", len(segment.split())*(1/threshold), \"seg:\", segment)\n",
    "                        if count >= len(segment.split(\" \"))*(threshold/(threshold + 1)):\n",
    "                            intersect_more_more_than_threshold = True\n",
    "                            \n",
    "                                \n",
    "                    if (segment in block[\"text\"] or intersect_more_more_than_threshold):\n",
    "                        interesting_sections.append({\n",
    "                            \"page\": block[\"page\"],\n",
    "                            \"text\": segment if segment in block[\"text\"] else block[\"text\"],\n",
    "                            \"category\": \"main\",\n",
    "                            \"bbox\": block[\"bbox\"]\n",
    "                        })\n",
    "                        # print(segment)\n",
    "    if not interesting_points:\n",
    "        try:\n",
    "            response = llm.invoke(prompt)\n",
    "            # Extract segments between triple backticks\n",
    "            import re\n",
    "            segments = re.findall(r'```(.*?)```', response.content, re.DOTALL)\n",
    "            \n",
    "            for segment in segments:\n",
    "                segment = segment.strip()\n",
    "                # print(segment)\n",
    "                for block in blocks:\n",
    "                    if segment in block[\"text\"] and block[\"category\"] == \"main\":\n",
    "                        # print(block[\"page\"])\n",
    "                        interesting_sections.append({\n",
    "                            \"page\": block[\"page\"],\n",
    "                            \"text\": segment,\n",
    "                            \"category\": \"main\",\n",
    "                            \"bbox\": block[\"bbox\"]\n",
    "                        })\n",
    "                        break\n",
    "            with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"\\n\\n\".join(segments))\n",
    "        except Exception as e:\n",
    "            print(f\"Error during interesting point extraction: {e}\")\n",
    "        \n",
    "    return interesting_sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_interesting_points(pdf_path, interesting_points, output_path):\n",
    "    \"\"\"Add highlights to the interesting points in the PDF with improved fuzzy matching.\"\"\"\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    \n",
    "    # Using cyan highlight color for main content\n",
    "    highlight_color = (0, 1, 1)  # RGB for cyan\n",
    "    fail_count = 0\n",
    "    success_count = 0\n",
    "    \n",
    "    for point in interesting_points:\n",
    "        page = doc[point[\"page\"]]\n",
    "        text = point[\"text\"]\n",
    "        if not text:\n",
    "            print(f\"Empty text for page {point['page']}\")\n",
    "            continue\n",
    "            \n",
    "        # Try exact match first\n",
    "        text_instances = page.search_for(text)\n",
    "        \n",
    "        # If exact match fails, try with these fallback methods:\n",
    "        if not text_instances:\n",
    "            # Method 1: Try normalized text (remove extra whitespace)\n",
    "            normalized_text = ' '.join(text.split())\n",
    "            text_instances = page.search_for(normalized_text)\n",
    "            \n",
    "            # Method 2: Try with key phrases (for longer text segments)\n",
    "            if not text_instances and len(normalized_text.split()) > 10:\n",
    "                # Extract significant phrases (5-8 words)\n",
    "                words = normalized_text.split()\n",
    "                for i in range(len(words) - 5):\n",
    "                    phrase = ' '.join(words[i:i+min(8, len(words)-i)])\n",
    "                    if len(phrase) > 15:  # Only phrases with enough content\n",
    "                        phrase_instances = page.search_for(phrase)\n",
    "                        if phrase_instances:\n",
    "                            text_instances = phrase_instances\n",
    "                            break\n",
    "            \n",
    "            # Method 3: Use key sentences if text contains multiple sentences\n",
    "            if not text_instances and '.' in normalized_text:\n",
    "                sentences = [s.strip() for s in normalized_text.split('.') if len(s.strip()) > 15]\n",
    "                for sentence in sentences:\n",
    "                    sentence_instances = page.search_for(sentence)\n",
    "                    if sentence_instances:\n",
    "                        text_instances = sentence_instances\n",
    "                        break\n",
    "        \n",
    "        # Highlight found instances or use bbox as fallback\n",
    "        if text_instances:\n",
    "            for inst in text_instances:\n",
    "                highlight = page.add_highlight_annot(inst)\n",
    "                highlight.set_colors(stroke=highlight_color)\n",
    "                highlight.update()\n",
    "            success_count += 1\n",
    "        elif \"bbox\" in point:\n",
    "            r = page.add_highlight_annot(point[\"bbox\"])\n",
    "            r.set_colors(stroke=highlight_color)    \n",
    "            r.update()\n",
    "            success_count += 1\n",
    "        else:\n",
    "            fail_count += 1\n",
    "    \n",
    "    print(f\"Successfully highlighted {success_count} segments\")\n",
    "    print(f\"Failed to highlight {fail_count} segments\")\n",
    "    \n",
    "    # Save the highlighted PDF\n",
    "    doc.save(output_path)\n",
    "    doc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: D:\\DATA300\\AudioBookSum\\pdf\\Clopath.pdf\n",
      "pyMuPDF\n",
      "Extracted 42 text blocks\n",
      "Classified text blocks\n",
      "Chunked text for processing\n",
      "Identified 0 interesting points in main content\n",
      "[]\n",
      "Successfully highlighted 0 segments\n",
      "Failed to highlight 0 segments\n",
      "Created highlighted PDF: D:\\DATA300\\AudioBookSum\\pdf\\Clopath_highlighted.pdf\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_pdf_path = r'D:\\DATA300\\AudioBookSum\\pdf\\Clopath.pdf'\n",
    "pdf_file = Path(input_pdf_path)\n",
    "assert pdf_file.is_file()\n",
    "base_name = os.path.splitext(input_pdf_path)[0]\n",
    "output = f\"{base_name}_highlighted.pdf\"\n",
    "\n",
    "\n",
    "# Initialize LLM\n",
    "try:\n",
    "    llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash', temperature=0.7)\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Gemini LLM: {e}\")\n",
    "    print(\"Make sure you have set GOOGLE_API_KEY in your environment or .env file\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"Processing PDF: {input_pdf_path}\")\n",
    "\n",
    "# Extract text and bounding boxes\n",
    "words, extract_method = extract_text(input_pdf_path)\n",
    "print(extract_method)\n",
    "\n",
    "print(f\"Extracted {len(words)} text blocks\")\n",
    "\n",
    "# Classify text blocks\n",
    "classified_blocks = classify_text_blocks(words, extract_method)\n",
    "print(\"Classified text blocks\")\n",
    "# Considering Chunking before classification\n",
    "# with open('content_extra.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(\" \".join([block[\"text\"] for block in classified_blocks if block[\"category\"] == \"extra\"]))\n",
    "# with open('content.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(\" \".join([block[\"text\"] for block in classified_blocks if block[\"category\"] == \"main\"]))\n",
    "# with open('content_footnote.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(\" \".join([block[\"text\"] for block in classified_blocks if block[\"category\"] == \"footnote\"]))\n",
    "# # Chunk text\n",
    "chunked_data = chunk_text(classified_blocks)\n",
    "print(\"Chunked text for processing\")\n",
    "\n",
    "# # Identify interesting points (main content only)\n",
    "interesting_points = identify_interesting_points(chunked_data, llm, classified_blocks, f\"{base_name}_interesting_points.txt\")  # Save to file\n",
    "# load from memory\n",
    "print(f\"Identified {len(interesting_points)} interesting points in main content\")\n",
    "print(interesting_points)\n",
    "# # Highlight interesting points in the PDF\n",
    "highlight_interesting_points(input_pdf_path, interesting_points, output)\n",
    "print(f\"Created highlighted PDF: {output}\")\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
