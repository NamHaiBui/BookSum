[
  {
    "name": "[Page:0] Document Root",
    "children": [
      {
        "name": "[Page:0] Neural Networks are Decision Trees",
        "children": []
      },
      {
        "name": "[Page:0] Caglar Aytekin\nAI Lead\nAAC Technologies",
        "children": []
      },
      {
        "name": "[Page:0] 2022\nOct\n25",
        "children": []
      },
      {
        "name": "[Page:0] Abstract",
        "children": []
      },
      {
        "name": "[Page:0] arXiv:2210.05189v3",
        "children": []
      },
      {
        "name": "[Page:0] 1. Introduction",
        "children": []
      },
      {
        "name": "[Page:0] Conversion between neural networks and interpretable\nby-design models -such as decision trees- has been a topic\nof interest. In [8], a method was devised to initialize neural\nnetworks with decision trees. [9, 19, 25] also provides neu-\nral network equivalents of decision trees. The neural net-\nworks in these works have speciﬁc architectures, thus the\nconversion lacks generalization to any model. In [24], neu-\nral networks were trained in such a way that their decision\nboundaries can be approximated by trees. This work does\nnot provide a correspondence between neural networks and\ndecision trees, and merely uses the latter as a regulariza-\ntion. In [7], a neural network was used to train a decision\ntree. Such tree distillation is an approximation of a neural\nnetwork and not a direct conversion, thus performs poorly\non the tasks that the neural network was trained on. [Page:1] a neural network can be found for either fully connected or\nconvolutional neural networks which may include skip lay-\ners and normalizations as well. Besides the interpretability\naspect, we show that the induced tree is also advantageous\nto the corresponding neural network in terms of computa-\ntional complexity, at the expense of increased storage mem-\nory. [Page:1] Upon writing this paper, we have noticed the following\nworks having overlaps with ours [28], [3], [15], [21], es-\npecially for feedforward ReLU networks. We extend the\nﬁndings in these works to any activation function and also\nrecurrent neural networks.",
        "children": []
      },
      {
        "name": "[Page:1] 2. Decision Tree Analysis of Neural Networks",
        "children": []
      },
      {
        "name": "[Page:1] 2.1. Fully Connected Networks",
        "children": []
      },
      {
        "name": "[Page:1] WT n−1σ(WT n−2σ(...WT σ(WT NN(x0) = x0)))\n1 0\nσ(WT i−1σ(...WT σ(WT xi = x0)))\n1 0",
        "children": []
      },
      {
        "name": "[Page:1] WT σ(WT WT ⊙(WT i−1xi−1) = (ai−1 i−1xi−1))\ni i",
        "children": []
      },
      {
        "name": "[Page:1] WT σ(WT WT ⊙ai−1)T i−1xi−1) = (Wi i−1xi−1\ni",
        "children": []
      },
      {
        "name": "[Page:1] ⊙an−2)T ⊙an−3)T NN(x0) = (Wn−1 (Wn−2\nWT ⊙a0)T ...(W1 x0\n0",
        "children": []
      },
      {
        "name": "[Page:1] T ˆW WT ⊙ai−1)T ⊙a0)T = (Wi ...(W1 Ci−1 i 0\nT ˆW WT = x0 xi Ci−1 i i",
        "children": []
      },
      {
        "name": "[Page:2] WT > 0 00x0\nWT WT > 0 > 0 01x0 01x0\nT T T T ˆ ˆ ˆ ˆ > 0 > 0 > 0 > 0 W10 x0 W10 x0 W10 x0 W10 x0 00 01 10 11\nT T T T T T T T ˆ ˆ ˆ ˆ ˆ ˆ ˆ ˆ W20 W20 W20 W20 W20 W20 W20 W20 x0 x0 x0 x0 x0 x0 x0 x0 000 001 010 011 100 101 110 111",
        "children": []
      },
      {
        "name": "[Page:2] may occur violating and redundant rules that would pro-\nvide lossless pruning of the NN-equivalent tree. Another\nobservation is that, it is highly likely that not all categories\nwill be realized during training due to the possibly much\nlarger number of categories (tree leaves) than training data.\nThese categories can be pruned as well based on the ap-\nplication, and the data falling into these categories can be\nconsidered invalid, if the application permits. In the next\nsection, we show that such redundant, violating and unre-\nalized categories indeed exist, by analysing decision trees\nof some neural networks. But before that, we show that the\ntree equivalent of a neural network exists for skip connec-\ntions, normalizations, convolutions, other activation func-\ntions and recurrence.",
        "children": []
      },
      {
        "name": "[Page:2] We analyse a residual neural network of the following type: [Page:3] 2.1.2 [Page:3] Normalization Layers [Page:3] A separate analysis is not needed for any normalization\nlayer, as popular normalization layers are linear, and after\ntraining, they can be embedded into the linear layer that it\ncomes after or before, in pre-activation or post-activation\nnormalizations respectively.",
        "children": []
      },
      {
        "name": "[Page:3] 2.2. Convolutional Neural Networks",
        "children": []
      },
      {
        "name": "[Page:3] ∗σ(Kn−2 ∗σ(...σ(K0 ∗F0)) CNN(F0) = Kn−1\n∗σ(...σ(K0 ∗F0)) = σ(Ki−1 Fi",
        "children": []
      },
      {
        "name": "[Page:3] ∗σ(Ki−1 ∗Fi−1) ⊙ai−1) ∗(Ki−1 ∗Fi−1) = (Ki Ki (10)",
        "children": []
      },
      {
        "name": "[Page:3] ˆKi ⊙ai−1) ∗... ∗(K1 ⊙a0) ∗K0 = (Ki ci−1",
        "children": []
      },
      {
        "name": "[Page:3] ˆKi ∗x0 ∗xi = Ki ci−1",
        "children": []
      },
      {
        "name": "[Page:3] 2.3. Continuous Activation Functions",
        "children": []
      },
      {
        "name": "[Page:3] 2.4. Recurrent Networks",
        "children": []
      },
      {
        "name": "[Page:3] h(t−1) h(t) σ(WT UT x(t)) = +\nVT h(t) o(t) =",
        "children": []
      },
      {
        "name": "[Page:3] h(t−1) h(t) ⊙(WT UT a(t) x(t)) = +",
        "children": []
      },
      {
        "name": "[Page:3] 1\nY h(t) (WT ⊙a(j)))WT h(0) a(t) ⊙( =\nj=(t−1)",
        "children": []
      },
      {
        "name": "[Page:3] t iY\nX (WT ⊙a(j)))UT +a(t) x(i) ⊙ (\ni=1 j=(t−1)",
        "children": []
      },
      {
        "name": "[Page:3] t ˆW1WT ˆWiUT X h(t) h(0) a(t) a(t) x(i) ⊙c1 ⊙ = + ci\ni=1 iY\nT ˆW (WT ⊙a(j)) = ci i\nj=(t−1)\n(15) [Page:4] −1.16 x <\nx < 0.32 x < 0.32\nx > 1 x > 0.54 x > 0.52 x > 0.39\n−0.1 −0.1 −0.7 −0.7 −0.38 −0.38 x < < x < 0.11 x < 0.11 x < x < x < x < x0\nT T T T T T T T T T T T T T T T ˆW ˆW ˆW ˆW ˆW ˆW ˆW ˆW ˆW ˆW ˆW ˆW ˆW ˆW ˆW ˆW x x x x x x x x x x x x x0 x0 x x 4 5 6 7 0 1 8 9 10 11 12 13 14 15 2 3 [Page:4] x2 y = Figure 2. Decision Tree for a Regression Neural Network",
        "children": []
      },
      {
        "name": "[Page:4] −1.16 x <\n−3.67x −3.22 x < 0.32\nx > 1 x < 0.11.\n−2.83 −0.50 −1.00x −0.12 0.55x + 0.09 3.47x 2.37x\n(a) Cleaned Tree",
        "children": []
      },
      {
        "name": "[Page:4] o(t) Combining Eq. 15 and Eq. 12, one can write as\nfollows.",
        "children": []
      },
      {
        "name": "[Page:4] 3. Experimental Results [Page:5] 3 layers with leaky-ReLU activations, except for last layer\n2 which has sigmoid activation. Each layer has ﬁlters ex-\n1. cept for the last layer which has The cleaned decision\ntree induced by the trained network is shown in Fig. 4. The\ndecision tree ﬁnds many categories whose boundaries are\ndetermined by the rules in the tree, where each category\nis assigned a single class. In order to better visualize the\ncategories, we illustrate them with different colors in Fig.\n5. One can make several deductions from the decision tree\nsuch as some regions are very well-deﬁned, bounded and\nthe classiﬁcations they make are perfectly in line with the\ntraining data, thus these regions are very reliable. There are\nunbounded categories which help obtaining accurate classi-\nﬁcation boundaries, yet fail to provide a compact represen-\ntation of the training data, these may correspond to inaccu-\nrate extrapolations made by neural decisions. There are also\nsome categories that emerged although none of the training\ndata falls to them.\nBesides the interpretability aspect, the decision tree rep-\nresentation also provides some computational advantages.\nIn Table 1, we compare the number of parameters, ﬂoat-\npoint comparisons and multiplication or addition operations\nof the neural network and the tree induced by it. Note that\nthe comparisons, multiplications and additions in the tree\nrepresentation are given as expected values, since per each\ncategory depth of the tree is different. As the induced tree\nis an unfolding of the neural network, it covers all possi-\nble routes and keeps all possible effective ﬁlters in mem-\nory. Thus, as expected, the number of parameters in the tree\nrepresentation of a neural network is larger than that of the\ni, network. In the induced tree, in every layer a maximum [Page:6] mi of ﬁlters are applied directly on the input, whereas in the\nmi neural network always ﬁlters are applied on the previous\nfeature, which is usually much larger than the input in the\nfeature dimension. Thus, computation-wise, the tree repre-\nsentation is advantageous compared to the neural network\none.",
        "children": []
      },
      {
        "name": "[Page:4] First, we make a toy experiment where we ﬁt a neural\nx2 y = 3 network to: equation. The neural network has",
        "children": []
      },
      {
        "name": "[Page:4] 2 dense layers with ﬁlters each, except for last layer which\nhas 1 ﬁlter. The network uses leaky-ReLU activations after\nfully connected layers, except for the last layer which has\n0.3 no post-activation. We have used negative slope of for\nleaky-ReLU which is the default value in Tensorﬂow [1].\n5000 (x, y) x The network was trained with pairs where was\n[−2.5, 2.5] regularly sampled from interval. Fig. 2 shows\nthe decision tree corresponding to the neural network. In the\ntree, every black rectangle box indicates a rule, left child\nfrom the box means the rule does not hold, and the right\nchild means the rule holds. For better visualization, the\nwT x + β > 0 rules are obtained via converting to direct\nx. inequalities acting on This can be done for the partic-\nx2, y = x ular regression since is a scalar. In every leaf,\nthe network applies a linear function -indicated by a red\nrectangle- based on the decisions so far. We have avoided\nwriting these functions explicitly due to limited space. At\nﬁrst glance, the tree representation of a neural network in\nPn−2 mi 24 2 = = 16 this example seems large due to the i\ncategorizations. However, we notice that a lot of the rules\nin the decision tree is redundant, and hence some paths in\nthe decision tree becomes invalid. An example to redundant\n−1.16 x < 0.32 x < rule is checking after rule holds. This [Page:5] −0.98x −0.49y + 0.95\n−1.6x −0.07 −1.6x −0.07 + 0.2y + 0.2y\n−0.15x −0.22 −0.5x −0.27 + 0.19y + 0.41 0 0.5x + 0.52y + 0.64y\n−0.3y −0.46x −0.76y −1y −1y 1 0.45x + 0.05 1 + 0.94 1.51x + 1.03 1.51x + 1.03\n−1.35y −1.44 −2.72x −3.53y −1.35y −3.17y −4.51y 0 1.6x 0 + 2.77 1.59x + 0.78 4.18x + 2.54 0 5.31x + 3.14\n0 1 0 1 0 1 0 1 0 1 [Page:5] Figure 4. Classiﬁcation Tree for a Half-Moon Classiﬁcation Neural Network [Page:5] Figure 5. Categorizations made by the decision tree for half-moon\ndataset",
        "children": []
      },
      {
        "name": "[Page:5] directly creates the invalid left child for this node. Hence,\nthe tree can be cleaned via removing the left child in this\ncase, and merging the categorization rule to the stricter one :\n−1.16 x < in the particular case. Via cleaning the decision\ntree in Fig. 2, we obtain the simpler tree in Fig. 3a, which\n5 16. 5 only consists of categories instead of The categories\nare directly visible also from the model response in Fig. 3b.\nThe interpretation of the neural network is thus straightfor-\nward: for each region whose boundaries are determined via\nthe decision tree representation, the network approximates\nx2 y = the non-linear equation by a linear equation. One\ncan clearly interpret and moreover make deduction from the\ndecision tree, some of which are as follows. The neural\nnetwork is unable to grasp the symmetrical nature of the\nregression problem which is evident from the fact that the\ndecision boundaries are asymmetrical. The region in below\n−1.16 1 and above is unbounded and thus neural decisions\nlose accuracy as x goes beyond these boundaries.\nNext, we investigate another toy problem of classifying\nhalf-moons and analyse the decision tree produced by a neu-\nral network. We train a fully connected neural network with",
        "children": []
      },
      {
        "name": "[Page:6] 4. Conclusion",
        "children": []
      },
      {
        "name": "[Page:6] References [Page:7] [22] Andreas Veit and Serge Belongie. Convolutional networks\nProceedings of the Euro- with adaptive inference graphs. In\npean Conference on Computer Vision (ECCV), pages 3–18,\n2018. 1\n[23] Alvin Wan, Lisa Dunlap, Daniel Ho, Jihan Yin, Scott Lee,\nHenry Jin, Suzanne Petryk, Sarah Adel Bargal, and Joseph E\narXiv Gonzalez. Nbdt: neural-backed decision trees.\npreprint arXiv:2004.00221, 2020. 1\n[24] Mike Wu, Michael Hughes, Sonali Parbhoo, Maurizio Zazzi,\nVolker Roth, and Finale Doshi-Velez. Beyond sparsity: Tree\nPro- regularization of deep models for interpretability. In\nceedings of the AAAI conference on artiﬁcial intelligence,\nvolume 32, 2018. 1\n[25] Yongxin Yang, Irene Garcia Morillo, and Timothy M\narXiv preprint Hospedales. Deep neural decision trees.\narXiv:1806.06988, 2018. 1\n[26] Matthew D Zeiler and Rob Fergus. Visualizing and under-\nEuropean conference on standing convolutional networks. In\ncomputer vision, pages 818–833. Springer, 2014. 1\n[27] Jianming Zhang, Sarah Adel Bargal, Zhe Lin, Jonathan\nBrandt, Xiaohui Shen, and Stan Sclaroff. Top-down neu-\nInternational Journal ral attention by excitation backprop.\nof Computer Vision, 126(10):1084–1102, 2018. 1\n[28] Liwen Zhang, Gregory Naitzat, and Lek-Heng Lim. Tropical\nInternational Confer- geometry of deep neural networks. In\nence on Machine Learning, pages 5824–5832. PMLR, 2018.\n2\n[29] Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva,\nand Antonio Torralba. Learning deep features for discrimina-\nProceedings of the IEEE conference on tive localization. In\ncomputer vision and pattern recognition, pages 2921–2929,\n2016. 1",
        "children": []
      }
    ]
  }
]